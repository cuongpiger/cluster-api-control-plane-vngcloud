{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import os\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas import evaluate\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "from datasets import Dataset\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://61.28.230.60:11434\"\n",
    "\n",
    "llama3_model_name = \"llama3.1:8b\"\n",
    "gemma2_model_name = \"gemma2:9b\"\n",
    "\n",
    "pdf_path = \"./data/google-2023-environmental-report.pdf\"\n",
    "user_query = \"What are Google's environmental initiatives?\"\n",
    "\n",
    "collection_name = \"google_environmental_report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OllamaEmbeddings(model=llama3_model_name, base_url=base_url)\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=llama3_model_name, base_url=base_url, temperature=0.1, num_predict=1024\n",
    ")\n",
    "\n",
    "generator_llm = ChatOllama(\n",
    "    model=llama3_model_name, base_url=base_url, temperature=0.1, num_predict=1024\n",
    ")\n",
    "\n",
    "critic_llm = ChatOllama(\n",
    "    model=gemma2_model_name, base_url=base_url, temperature=0.1, num_predict=1024\n",
    ")\n",
    "\n",
    "critic_llm_embedding = OllamaEmbeddings(model=gemma2_model_name, base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PDF file and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PdfReader(pdf_path)\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental \n",
      "Report\n",
      "2023What’s \n",
      "inside\n",
      "About this report\n",
      "Google’s 2023 Environmental Report provides an overview of our environmental \n",
      "sustainability strategy and targets and our annual progress towards them. 1  \n",
      "This report features data, performance highlights, and progress against our targets f\n"
     ]
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "\n",
    "splits = character_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_documents = [\n",
    "    Document(page_content=text, metadata={\"id\": str(i), \"source\": \"dense\"})\n",
    "    for i, text in enumerate(splits)\n",
    "]\n",
    "sparse_documents = [\n",
    "    Document(page_content=text, metadata={\"id\": str(i), \"source\": \"sparse\"})\n",
    "    for i, text in enumerate(splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=dense_documents,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=collection_name,\n",
    "    client=chroma_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "sparse_retriever = BM25Retriever.from_documents(sparse_documents, k=10)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, sparse_retriever], weights=[0.5, 0.5], c=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RETRIEVAL and GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prompt - ignore LangSmith warning, you will not need langsmith for this coding exercise\n",
    "prompt = hub.pull(\"jclemens24/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance check prompt\n",
    "relevance_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following question and retrieved context, determine if the context is relevant to the question.\n",
    "\n",
    "    Question: {question}\n",
    "    Retrieved Context: {retrieved_context}\n",
    "    \n",
    "    Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
    "    Return ONLY the numeric score, without any additional text or explanation.\n",
    "\n",
    "    Relevance Score:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(llm_output):\n",
    "    try:\n",
    "        score = float(llm_output.strip())\n",
    "        return score\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Chain it all together with LangChain\n",
    "def conditional_answer(x):\n",
    "    relevance_score = extract_score(x[\"relevance_score\"])\n",
    "    if relevance_score < 4:\n",
    "        return \"I don't know.\"\n",
    "    else:\n",
    "        return x[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | RunnableParallel(\n",
    "        {\n",
    "            \"relevance_score\": (\n",
    "                RunnablePassthrough()\n",
    "                | (\n",
    "                    lambda x: relevance_prompt_template.format(\n",
    "                        question=x[\"question\"], retrieved_context=x[\"context\"]\n",
    "                    )\n",
    "                )\n",
    "                | llm\n",
    "                | str_output_parser\n",
    "            ),\n",
    "            \"answer\": (RunnablePassthrough() | prompt | llm | str_output_parser),\n",
    "        }\n",
    "    )\n",
    "    | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_similarity = RunnableParallel(\n",
    "    {\"context\": dense_retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_hybrid = RunnableParallel(\n",
    "    {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question to Similarity Search: What are Google's environmental initiatives?\n",
      "\n",
      "Relevance Score: 4\n",
      "\n",
      "Final Answer:\n",
      "Google's environmental initiatives include:\n",
      "\n",
      "1. **CDP (formerly known as the Carbon Disclosure Project)**: Google has been reporting its carbon footprint to CDP since 2009 and has partnered with CDP to host its annual conference, a hack-a-thon, and to launch CDP scores in Google Finance.\n",
      "2. **Clean Energy Buyers Association (CEBA)**: Google was involved in the creation of CEBA in 2018 and continues to serve as the Board Chair of this organization.\n",
      "3. **Exponential Roadmap Initiative**: Google joined this initiative in 2021, which is committed to halving emissions before 2030 towards net-zero emissions by no later than 2050.\n",
      "4. **First Movers Coalition**: Google joined this coalition in 2022 and committed to contract for durable and scalable net carbon dioxide removal to be achieved by the end of 2030.\n",
      "5. **Google Earth Engine**: This platform provides access to reliable, up-to-date insights on how our planet is changing, and has been expanded to include businesses and governments worldwide as an enterprise-grade service through Google Cloud.\n",
      "6. **Sustainable campuses**: Google's new Bay View campus is all-electric, net water-positive, restores over 17 acres of high-value nature, and incorporates the leading principles of circular design.\n",
      "7. **Supplier engagement**: Google works with many suppliers that are committed to sustainability and partners with them to develop decarbonization roadmaps and build essential data infrastructure.\n",
      "8. **Global Covenant of Mayors for Climate & Energy (GCoM)**: Google's Environmental Insights Explorer was developed in partnership with GCoM, which supports city climate action with useful and accessible data and insights.\n",
      "9. **ICLEI partnerships**: Google is a partner of the regional secretariats of ICLEI—Local Governments for Sustainability—in Africa, Europe, and the U.S., supporting sustainable city development projects with data and insights from Google's Environmental Insights Explorer.\n",
      "\n",
      "Additionally, Google has implemented various initiatives to reduce its own emissions, such as:\n",
      "\n",
      "* **Electric buses**: Google launched an expansion of all-electric buses for the Bay Area in 2022.\n",
      "* **Commuter shuttles**: Many campuses offer commuter shuttles to reduce individual vehicle trips.\n",
      "* **Eco-friendly routing**: Google Maps offers eco-friendly routing features that can help prevent carbon emissions.\n",
      "\n",
      "These are just a few examples of Google's environmental initiatives.\n",
      "\n",
      "\n",
      "Retrieved Documents:\n",
      "Document 1: Document ID: 8 source: dense\n",
      "Content:\n",
      "Given the scale of the problem, innovation  will also be \n",
      "key to getting us to a better future. In order to push the \n",
      "frontiers of innovation, Google has long had a world-class research organization that’s been at the forefront of AI and machine learning. These solutions can help in predicting \n",
      "more extreme weather (flood forecasting, for instance), optimizing systems from traffic lights to car routes, and mitigating climate change in new ways, for example. \n",
      "In our 2023 Environmental Report, we’re highlighting how \n",
      "these themes of information and innovation run through much of our work:\n",
      "For information, we’ll feature Google Trends  \n",
      "insights alongside key initiatives to show how our work is informed by societal trends and expectations.\n",
      "And for innovation, we’ll call out the many  \n",
      "places where AI is helping to break down  barriers and advance our work.\n",
      "\n",
      "Document 2: Document ID: 339 source: dense\n",
      "Content:\n",
      "CDP  (formerly \n",
      "known as the Carbon Disclosure Project)In addition to reporting our carbon footprint to CDP since 2009, we’ve partnered with CDP to host its annual conference, a hack-a-thon, and to launch CDP scores in Google Finance, making corporate carbon disclosure information more widely available.\n",
      "Clean Energy Buyers Association (CEBA)Google was actively involved in the creation of CEBA in 2018, chairing the Interim Board of Directors during its transition from an NGO-led effort into a corporate-led trade association. A Google representative continues to serve as the Board Chair of this organization. Google provided initial financial support for the development of the organization and in 2022, Google.org provided a $1 million grant to support CEBA’s international expansion.\n",
      "\n",
      "Document 3: Document ID: 342 source: dense\n",
      "Content:\n",
      "Exponential Roadmap Initiative In 2021, we joined the Exponential Roadmap Initiative and the U.N. Race to Zero Campaign , the largest ever \n",
      "alliance committed to halving emissions before 2030 towards net-zero emissions by no later than 2050.\n",
      "First Movers CoalitionAt the World Economic Forum Annual Meeting in 2022, Google joined  the First Movers Coalition . As a champion \n",
      "for the Carbon Dioxide Removal sector , Google committed to contract for durable and scalable net carbon \n",
      "dioxide removal to be achieved by the end of 2030.\n",
      "FrontierIn 2022, we committed $200 million to Frontier, an advanced market commitment that will accelerate the development of carbon removal technologies by guaranteeing future demand. We were one of five companies that made a $925 million total pledge to Frontier. As one of its founding members, we’re helping to guide overall strategy and governance.\n",
      "\n",
      "Document 4: Document ID: 71 source: dense\n",
      "Content:\n",
      "humanity, such as environmental degradation and climate change, and we see exciting opportunities for further \n",
      "impact. AI is embedded into many of our sustainability \n",
      "initiatives—including detecting and forecasting floods and \n",
      "wildfires , helping people and cities adapt to extreme heat , \n",
      "and protecting critical species habitat .  \n",
      "We’re leveraging this unique suite of capabilities in three key \n",
      "ways: supporting partners, investing in breakthrough \n",
      "innovation , and creating ecosystems for collaboration .\n",
      "Governments, aid organizations, and individuals can use Flood Hub to take timely action and prepare for riverine floods,  \n",
      "seeing locally relevant flood data and forecasts up to 7 days in advance.   22\n",
      "2023 Environmental Report  Supporting partners\n",
      "We’re building partnerships to advance sustainability \n",
      "goals through technology across three key groups: governments and intergovernmental organizations; customers and commercial partners; and researchers, academics, and NGOs.\n",
      "\n",
      "Document 5: Document ID: 281 source: dense\n",
      "Content:\n",
      "NGOs, governments, and academics around the world to help address nature and biodiversity loss. Our most impactful technology in this area is Google Earth Engine , \n",
      "a leading technology platform for planetary-scale environmental monitoring such as land use change, the most significant driver of biodiversity loss. Additionally, we’ve helped launch other platforms that help protect nature, such as TraceMark , a sustainable sourcing solution that improves supply chain transparency. We also use AI to help partners unlock new advances, such as our machine learning model that helps the scientific community in detecting humpback whale sounds, or in finding hopeful signs of wildlife recovery  after wildfires.\n",
      "\n",
      "Document 6: Document ID: 283 source: dense\n",
      "Content:\n",
      "2023 Environmental Report  The journey ahead\n",
      "Our approach to protecting nature has important co-\n",
      "benefits. Protecting nature helps sequester carbon, and sequestering carbon helps preserve nature. Water stewardship helps nature thrive, and thriving ecosystems support water stewardship. By promoting circularity, we’re reducing the extraction of natural resources, which in turn protects against environmental degradation—a direct driver of biodiversity loss. For that reason, we’ll seek to evaluate these efforts with a more holistic view.\n",
      "While we’re excited about our work to protect and \n",
      "enhance nature and biodiversity through our campuses and technology, we recognize that we face some challenges, including:\n",
      " • Navigating the local complexities of biodiversity and ecosystem health, as well as forging a broad set of partners to ensure collective action.\n",
      " • Feeding a global workforce responsibly and sustainably while supporting agrobiodiversity and regenerative agriculture practices.\n",
      "\n",
      "Document 7: Document ID: 13 source: dense\n",
      "Content:\n",
      "2\n",
      "After two years of condensed reporting, we’re sharing a deeper dive into our approach in one place in our 2023 Environmental Report. In 2022, we continued to make measurable progress in many key ways, such as:\n",
      "• We enhanced and launched new sustainabilityproduct features , such as eco-friendly routing in\n",
      "Maps, which is estimated to have helped preventmore than 1.2 million metric tons of carbon emissionsfrom launch through 2022—equivalent to takingapproximately 250,000 fuel-based cars off the roadfor a year.\n",
      " 3\n",
      "• We expanded the availability of Google EarthEngine —which provides access to reliable, up-to-\n",
      "date insights on how our planet is changing—toinclude businesses and governments worldwide as anenterprise-grade service through Google Cloud.• We opened our new Bay View campus , which is\n",
      "all-electric, net water-positive, restores over 17 acresof high-value nature, and incorporates the leadingprinciples of circular design.\n",
      "\n",
      "Document 8: Document ID: 124 source: dense\n",
      "Content:\n",
      "including policy engagement, trade associations, memberships, and partnerships, see the Governance  \n",
      "and Engagement  section.\n",
      "Challenges to address\n",
      "While we’re excited about our net-zero emissions journey, we recognize that we face many challenges. For example:\n",
      "Growing energy needs\n",
      "• As we work towards our absolute 50% emissions reduction target, our business is continuing to evolve to meet the needs of a rapidly digitalizing world, and to harness the opportunities presented by  AI technology.\n",
      "• Our operations and value chain are global and involve a diverse range of industries, which means we must make progress within hard-to-abate sectors and carbon-intensive geographies, such as the Asia Pacific region. \n",
      "• We have a large number of different suppliers, both direct and indirect, each with climate programs that differ widely in maturity. In some cases, this limits our ability to successfully influence them, and to collect the data needed to accurately estimate our  Scope 3 emissions.\n",
      "\n",
      "Document 9: Document ID: 149 source: dense\n",
      "Content:\n",
      "2e emissions in 2022. 80 \n",
      "Many campuses offer commuter shuttles  to reduce \n",
      "individual vehicle trips. In 2022, we launched an  expansion of our all-electric buses for the Bay Area and are introducing these throughout 2023 to replace our existing fleet. For 2022, our shuttle buses in the Bay Area produced savings of more than 10,000 tCO\n",
      "2e emissions—\n",
      "the equivalent of avoiding more than 41 million vehicle km (25 million vehicle miles) or taking on average more than 2,000 cars off the road for a year.\n",
      " 812022 HIGHLIGHT\n",
      "Google shuttle buses in the Bay Area \n",
      "produced savings of more than 10,000 tCO\n",
      "2e emissions—the equivalent of \n",
      "taking on average more than 2,000 cars off the road for a year.\n",
      " 82 \n",
      "Supplier engagement\n",
      "We work with many suppliers that are committed to \n",
      "sustainability, and we’re partnering with them to develop decarbonization roadmaps and build essential data infrastructure to accurately quantify emissions and reductions across the value chain.\n",
      "\n",
      "Document 10: Document ID: 343 source: dense\n",
      "Content:\n",
      "Global Covenant of Mayors for Climate & Energy  (GCoM)Google’s Environmental Insights Explorer was developed in partnership with GCoM through a shared vision to support city climate action with useful and accessible data and insights. Today, GCoM is a strategic partner, sharing EIE data with its alliance of cities and local governments to accelerate climate action. \n",
      "ICLEI AfricaICLEI EuropeICLEI USAGoogle is a partner of the regional secretariats of ICLEI—Local Governments for Sustainability—in Africa, Europe, and the U.S. Through these partnerships, ICLEI regional teams support sustainable city development projects  \n",
      "with data and insights from Google’s Environmental Insights Explorer. Additionally, in 2022, Google.org  provided \n",
      "a $10 million grant to ICLEI to support 10 nonprofit-led projects in the United States and Europe that help cities accelerate their sustainable transition through data-driven environmental and climate action at the local level.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question - Submitted to the similarity / dense vector search\n",
    "result = rag_chain_similarity.invoke(user_query)\n",
    "retrieved_docs = result[\"context\"]\n",
    "\n",
    "print(f\"Original Question to Similarity Search: {user_query}\\n\")\n",
    "print(f\"Relevance Score: {result['answer']['relevance_score']}\\n\")\n",
    "print(f\"Final Answer:\\n{result['answer']['final_answer']}\\n\\n\")\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(\n",
    "        f\"Document {i}: Document ID: {doc.metadata['id']} source: {doc.metadata['source']}\"\n",
    "    )\n",
    "    print(f\"Content:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question to Dense Search: What are Google's environmental initiatives?\n",
      "\n",
      "Relevance Score: 5\n",
      "\n",
      "Final Answer:\n",
      "It appears that you have provided a large block of text from Google's 2023 Environmental Report. I'll do my best to summarize the main points related to the question \"Emerging opportunities\" and specifically answer the implied question about AI for sustainability.\n",
      "\n",
      "**Summary of Emerging Opportunities:**\n",
      "\n",
      "The report highlights several emerging opportunities, including:\n",
      "\n",
      "1. **Artificial Intelligence (AI) for Sustainability**: Google is focusing on using AI to help individuals and organizations reduce their environmental impact.\n",
      "2. **Data-Driven Decision Making**: Google's data analytics tools are helping organizations make more informed decisions about their operations and supply chains.\n",
      "\n",
      "**Specific Answer:**\n",
      "\n",
      "The report mentions that Google is focusing on using AI to help build a more sustainable future, but it does not provide specific details about the initiatives or projects related to AI for sustainability. However, based on the context, it can be inferred that Google is exploring ways to use AI to:\n",
      "\n",
      "1. **Optimize Supply Chains**: By analyzing data and predicting energy demand, Google's customers (e.g., airlines) can optimize their operations and reduce emissions.\n",
      "2. **Predict Energy Demand**: Google's AI-powered tools can help predict wind power output, enabling utilities like Engie to make more informed decisions about energy production and distribution.\n",
      "\n",
      "Overall, the report suggests that Google is committed to using its technology and expertise to support sustainability efforts and reduce environmental impact.\n",
      "\n",
      "\n",
      "Retrieved Documents:\n",
      "Document 1: Document ID: 8 source: dense\n",
      "Content:\n",
      "Given the scale of the problem, innovation  will also be \n",
      "key to getting us to a better future. In order to push the \n",
      "frontiers of innovation, Google has long had a world-class research organization that’s been at the forefront of AI and machine learning. These solutions can help in predicting \n",
      "more extreme weather (flood forecasting, for instance), optimizing systems from traffic lights to car routes, and mitigating climate change in new ways, for example. \n",
      "In our 2023 Environmental Report, we’re highlighting how \n",
      "these themes of information and innovation run through much of our work:\n",
      "For information, we’ll feature Google Trends  \n",
      "insights alongside key initiatives to show how our work is informed by societal trends and expectations.\n",
      "And for innovation, we’ll call out the many  \n",
      "places where AI is helping to break down  barriers and advance our work.\n",
      "\n",
      "Document 2: Document ID: 150 source: sparse\n",
      "Content:\n",
      "sustainability, and we’re partnering with them to develop decarbonization roadmaps and build essential data infrastructure to accurately quantify emissions and reductions across the value chain.\n",
      "We engage with our suppliers—including hardware \n",
      "manufacturing and indirect services suppliers—to help reduce their energy consumption and GHG emissions, as stated in our Supplier Code of Conduct , which all \n",
      "suppliers are required to sign. We assess suppliers’ practices to report, manage, and reduce their emissions and incorporate this into our supplier scorecard.\n",
      "Reporting  \n",
      "environmental data\n",
      "We expect all our suppliers to report environmental data,\n",
      "\n",
      "Document 3: Document ID: 339 source: dense\n",
      "Content:\n",
      "CDP  (formerly \n",
      "known as the Carbon Disclosure Project)In addition to reporting our carbon footprint to CDP since 2009, we’ve partnered with CDP to host its annual conference, a hack-a-thon, and to launch CDP scores in Google Finance, making corporate carbon disclosure information more widely available.\n",
      "Clean Energy Buyers Association (CEBA)Google was actively involved in the creation of CEBA in 2018, chairing the Interim Board of Directors during its transition from an NGO-led effort into a corporate-led trade association. A Google representative continues to serve as the Board Chair of this organization. Google provided initial financial support for the development of the organization and in 2022, Google.org provided a $1 million grant to support CEBA’s international expansion.\n",
      "\n",
      "Document 4: Document ID: 309 source: sparse\n",
      "Content:\n",
      "that enable us to ensure that those we partner with are responsible environmental stewards. Along with having suppliers evaluate their operations, we perform our own ongoing due diligence and audits to verify compliance and to understand our supply chain’s current and potential risks.\n",
      "When we find that a supplier isn’t complying, we expect\n",
      "\n",
      "Document 5: Document ID: 342 source: dense\n",
      "Content:\n",
      "Exponential Roadmap Initiative In 2021, we joined the Exponential Roadmap Initiative and the U.N. Race to Zero Campaign , the largest ever \n",
      "alliance committed to halving emissions before 2030 towards net-zero emissions by no later than 2050.\n",
      "First Movers CoalitionAt the World Economic Forum Annual Meeting in 2022, Google joined  the First Movers Coalition . As a champion \n",
      "for the Carbon Dioxide Removal sector , Google committed to contract for durable and scalable net carbon \n",
      "dioxide removal to be achieved by the end of 2030.\n",
      "FrontierIn 2022, we committed $200 million to Frontier, an advanced market commitment that will accelerate the development of carbon removal technologies by guaranteeing future demand. We were one of five companies that made a $925 million total pledge to Frontier. As one of its founding members, we’re helping to guide overall strategy and governance.\n",
      "\n",
      "Document 6: Document ID: 298 source: sparse\n",
      "Content:\n",
      "2023 Environmental Report  Risk management\n",
      "Our Enterprise Risk Management (ERM) team is responsible \n",
      "for identifying, assessing, and reporting risks related to the company’s operations, financial performance, and reputation. As with financial, operational, and strategic risks, the team assesses environmental risks as part of the company’s overall risk management framework. The risks and opportunities identified through this process support public disclosures and inform Google’s environmental sustainability strategy. Our Chief Sustainability Officer and sustainability teams work to address risks by identifying opportunities to reduce the company’s environmental impacts from its operations and value chain, and through improving climate resilience. \n",
      "Climate-related \n",
      "risks\n",
      "Climate-related risks and opportunities have long time\n",
      "\n",
      "Document 7: Document ID: 71 source: dense\n",
      "Content:\n",
      "humanity, such as environmental degradation and climate change, and we see exciting opportunities for further \n",
      "impact. AI is embedded into many of our sustainability \n",
      "initiatives—including detecting and forecasting floods and \n",
      "wildfires , helping people and cities adapt to extreme heat , \n",
      "and protecting critical species habitat .  \n",
      "We’re leveraging this unique suite of capabilities in three key \n",
      "ways: supporting partners, investing in breakthrough \n",
      "innovation , and creating ecosystems for collaboration .\n",
      "Governments, aid organizations, and individuals can use Flood Hub to take timely action and prepare for riverine floods,  \n",
      "seeing locally relevant flood data and forecasts up to 7 days in advance.   22\n",
      "2023 Environmental Report  Supporting partners\n",
      "We’re building partnerships to advance sustainability \n",
      "goals through technology across three key groups: governments and intergovernmental organizations; customers and commercial partners; and researchers, academics, and NGOs.\n",
      "\n",
      "Document 8: Document ID: 311 source: sparse\n",
      "Content:\n",
      "In 2022, we audited a subset of our suppliers to verify \n",
      "compliance for the following environmental criteria: implementation of environmental management systems, environmental permits and reporting, product content restrictions, and resource efficiency, as well as management of hazardous substances, wastewater,  solid waste, and air emissions.\n",
      "Googlers chat among indoor plants at our Pier 57 office in New York City.   79\n",
      "2023 Environmental Report  Public policy and advocacy\n",
      "We know that strong public policy action is critical to \n",
      "creating prosperous, equitable, and resilient low-carbon economies around the world. \n",
      "The United Nations Framework Convention on Climate \n",
      "Change (UNFCCC)’s 2015 Paris Agreement states that humanity must “keep global temperature rise this century well below 2°C above pre-industrial levels.”\n",
      " 143 Google\n",
      "\n",
      "Document 9: Document ID: 281 source: dense\n",
      "Content:\n",
      "NGOs, governments, and academics around the world to help address nature and biodiversity loss. Our most impactful technology in this area is Google Earth Engine , \n",
      "a leading technology platform for planetary-scale environmental monitoring such as land use change, the most significant driver of biodiversity loss. Additionally, we’ve helped launch other platforms that help protect nature, such as TraceMark , a sustainable sourcing solution that improves supply chain transparency. We also use AI to help partners unlock new advances, such as our machine learning model that helps the scientific community in detecting humpback whale sounds, or in finding hopeful signs of wildlife recovery  after wildfires.\n",
      "\n",
      "Document 10: Document ID: 328 source: sparse\n",
      "Content:\n",
      "Sustainable \n",
      "consumption of \n",
      "public goods (e.g., \n",
      "“right to repair”)Google submitted comments to the European Commission’s public consultation regarding \n",
      "the promotion of repair and reuse of goods. We shared our views on the core principles to \n",
      "consider when introducing policy measures to promote repair and reuse horizontally, and for \n",
      "smartphones and tablets specifically.\n",
      "Body of European \n",
      "Regulators \n",
      "for Electronic \n",
      "Communications \n",
      "(BEREC)Google responded to a questionnaire  by BEREC in view of the development of key performance \n",
      "indicators to characterize the environmental impact of electronic communications, networks, \n",
      "devices, and services. We provided information about our environmental reporting practices \n",
      "and suggestions to help identify which indicators would provide relevant environmental \n",
      "information.\n",
      "Engagement with coalitions and sustainability initiatives\n",
      "RE-Source PlatformGoogle is a strategic partner and steering committee member of the RE-Source Platform, the\n",
      "\n",
      "Document 11: Document ID: 283 source: dense\n",
      "Content:\n",
      "2023 Environmental Report  The journey ahead\n",
      "Our approach to protecting nature has important co-\n",
      "benefits. Protecting nature helps sequester carbon, and sequestering carbon helps preserve nature. Water stewardship helps nature thrive, and thriving ecosystems support water stewardship. By promoting circularity, we’re reducing the extraction of natural resources, which in turn protects against environmental degradation—a direct driver of biodiversity loss. For that reason, we’ll seek to evaluate these efforts with a more holistic view.\n",
      "While we’re excited about our work to protect and \n",
      "enhance nature and biodiversity through our campuses and technology, we recognize that we face some challenges, including:\n",
      " • Navigating the local complexities of biodiversity and ecosystem health, as well as forging a broad set of partners to ensure collective action.\n",
      " • Feeding a global workforce responsibly and sustainably while supporting agrobiodiversity and regenerative agriculture practices.\n",
      "\n",
      "Document 12: Document ID: 415 source: sparse\n",
      "Content:\n",
      "chemistry\n",
      "• Governance and engagement - Risk management; Stakeholder engagement - Supplier \n",
      "engagement\n",
      "Engagement with external targets and initiatives related to sustainable \n",
      "supply chains • Wor king together - Our approach - Supporting partners - Cloud customers and  \n",
      "commercial partners\n",
      "• Governance and engagement - PartnershipsC12. Engagement\n",
      "Goals and targets Supplier environmental assessment-related targets• Introd uction - Targets and progress summary\n",
      "• Oper ating sustainably - Circular economy - Our approach - Working with suppliers\n",
      "Performance indicators New suppliers that were screened using environmental criteria • Governance and engagement - Risk management C12. Engagement\n",
      "Supplier renewable energy• Opera ting sustainably - Net-zero carbon - Our approach - Advancing carbon-free energy - \n",
      "CFE inv estmentsC2. Risks and opportunities\n",
      "Negative environmental impacts in the supply chain and actions taken• Oper ating sustainably - Circular economy - Supply chain\n",
      "\n",
      "Document 13: Document ID: 13 source: dense\n",
      "Content:\n",
      "2\n",
      "After two years of condensed reporting, we’re sharing a deeper dive into our approach in one place in our 2023 Environmental Report. In 2022, we continued to make measurable progress in many key ways, such as:\n",
      "• We enhanced and launched new sustainabilityproduct features , such as eco-friendly routing in\n",
      "Maps, which is estimated to have helped preventmore than 1.2 million metric tons of carbon emissionsfrom launch through 2022—equivalent to takingapproximately 250,000 fuel-based cars off the roadfor a year.\n",
      " 3\n",
      "• We expanded the availability of Google EarthEngine —which provides access to reliable, up-to-\n",
      "date insights on how our planet is changing—toinclude businesses and governments worldwide as anenterprise-grade service through Google Cloud.• We opened our new Bay View campus , which is\n",
      "all-electric, net water-positive, restores over 17 acresof high-value nature, and incorporates the leadingprinciples of circular design.\n",
      "\n",
      "Document 14: Document ID: 139 source: sparse\n",
      "Content:\n",
      "development and deployment of these materials.\n",
      "In 2022, we filed a patent for using machine \n",
      "learning technology to improve our ability to prevent emissions from refrigerant leaks.\n",
      "Data centers\n",
      "Google’s data centers are the engine of our company, powering products like Gmail, Google Cloud, Search, and YouTube for billions of people around the world. We’ve worked to make Google’s data centers some of the most efficient in the world, improving their environmental performance even as demand for our products has risen. We’ve done this by designing, building, and operating each one to maximize efficient use of energy, water, \n",
      "and ma\n",
      "terials.\n",
      "Our long-standing data center efficiency  efforts are\n",
      "\n",
      "Document 15: Document ID: 124 source: dense\n",
      "Content:\n",
      "including policy engagement, trade associations, memberships, and partnerships, see the Governance  \n",
      "and Engagement  section.\n",
      "Challenges to address\n",
      "While we’re excited about our net-zero emissions journey, we recognize that we face many challenges. For example:\n",
      "Growing energy needs\n",
      "• As we work towards our absolute 50% emissions reduction target, our business is continuing to evolve to meet the needs of a rapidly digitalizing world, and to harness the opportunities presented by  AI technology.\n",
      "• Our operations and value chain are global and involve a diverse range of industries, which means we must make progress within hard-to-abate sectors and carbon-intensive geographies, such as the Asia Pacific region. \n",
      "• We have a large number of different suppliers, both direct and indirect, each with climate programs that differ widely in maturity. In some cases, this limits our ability to successfully influence them, and to collect the data needed to accurately estimate our  Scope 3 emissions.\n",
      "\n",
      "Document 16: Document ID: 432 source: sparse\n",
      "Content:\n",
      "2023 Environmental Report  market structures. If no such structure exists, then Google defines the grid \n",
      "region as the electricity-balancing authority where our data centers are \n",
      "located. Outside of the United States, the grid region most often refers to \n",
      "the geographic boundary of a country, because most grid system operators \n",
      "operate at the national level. Certain regions that span multiple countries \n",
      "are well interconnected and could be considered as one grid; however, \n",
      "our grid mix calculations already include import and export considerations \n",
      "and therefore take into account power flows from neighboring grids. In \n",
      "the future, we may update our definition as we work with grid operators to \n",
      "better understand how transmission constraints or congestion impact CFE \n",
      "measurement within and across grid regions.\n",
      "91 Contracted CFE is the hourly electricity production from clean energy \n",
      "projects whose electricity and associated environmental attributes are\n",
      "\n",
      "Document 17: Document ID: 149 source: dense\n",
      "Content:\n",
      "2e emissions in 2022. 80 \n",
      "Many campuses offer commuter shuttles  to reduce \n",
      "individual vehicle trips. In 2022, we launched an  expansion of our all-electric buses for the Bay Area and are introducing these throughout 2023 to replace our existing fleet. For 2022, our shuttle buses in the Bay Area produced savings of more than 10,000 tCO\n",
      "2e emissions—\n",
      "the equivalent of avoiding more than 41 million vehicle km (25 million vehicle miles) or taking on average more than 2,000 cars off the road for a year.\n",
      " 812022 HIGHLIGHT\n",
      "Google shuttle buses in the Bay Area \n",
      "produced savings of more than 10,000 tCO\n",
      "2e emissions—the equivalent of \n",
      "taking on average more than 2,000 cars off the road for a year.\n",
      " 82 \n",
      "Supplier engagement\n",
      "We work with many suppliers that are committed to \n",
      "sustainability, and we’re partnering with them to develop decarbonization roadmaps and build essential data infrastructure to accurately quantify emissions and reductions across the value chain.\n",
      "\n",
      "Document 18: Document ID: 91 source: sparse\n",
      "Content:\n",
      "EV Suitability Assessment helps organizations monitor their fleet of vehicles and make choices that minimize environmental impact.\n",
      "Data analytics tools from Google Cloud are also helping \n",
      "airlines. Lufthansa Group partnered with Google Cloud \n",
      "and Google Research to develop a platform that facilitates better planning and management of daily flight operations.\n",
      "We’re helping organizations harness \n",
      "the power of data and AI to drive more intelligent supply chains.Renewable energy\n",
      "Wind farms are an important source of carbon-free electricity, but wind can fluctuate depending on the weather. Through Google Cloud, customers like Engie  (a global energy and renewables supplier) can optimize their wind portfolio in short-term power markets by predicting wind power output 36 hours ahead of actual generation  and making optimal hourly delivery \n",
      "commitments to the grid, a full day in advance.  \n",
      "Sustainability partner \n",
      "solutions\n",
      "Partner solutions are important to scale the impact for our\n",
      "\n",
      "Document 19: Document ID: 343 source: dense\n",
      "Content:\n",
      "Global Covenant of Mayors for Climate & Energy  (GCoM)Google’s Environmental Insights Explorer was developed in partnership with GCoM through a shared vision to support city climate action with useful and accessible data and insights. Today, GCoM is a strategic partner, sharing EIE data with its alliance of cities and local governments to accelerate climate action. \n",
      "ICLEI AfricaICLEI EuropeICLEI USAGoogle is a partner of the regional secretariats of ICLEI—Local Governments for Sustainability—in Africa, Europe, and the U.S. Through these partnerships, ICLEI regional teams support sustainable city development projects  \n",
      "with data and insights from Google’s Environmental Insights Explorer. Additionally, in 2022, Google.org  provided \n",
      "a $10 million grant to ICLEI to support 10 nonprofit-led projects in the United States and Europe that help cities accelerate their sustainable transition through data-driven environmental and climate action at the local level.\n",
      "\n",
      "Document 20: Document ID: 22 source: sparse\n",
      "Content:\n",
      "cled/ Ongoing  36% 41% 2025our consumer hardware product portfolio by 2025 renewable material (see pg. 62 )\n",
      "% plastic-free Ongoing  Make product packaging 100% plastic-free by 2025 97% 96% 2025packaging (see pg. 63 )\n",
      "Significant  Achieve UL 2799 Zero Waste to Landfill certification at all final \n",
      "Supply chain % of sites certified 9% 90% 2022 progress  assembly consumer hardware manufacturing sites by 2022\n",
      "(see pg. 65 )   9\n",
      "2023 Environmental Report  \n",
      "Emerging opportunities\n",
      "As the world becomes increasingly aware of the need for sustainability, individuals, businesses, and communities are  \n",
      "looking for new ways to reduce their environmental impact. Artificial intelligence (AI) and the power of information to help individuals and organizations reduce emissions are two emerging opportunities that Google is focusing on to help build a more sustainable future.\n",
      "AI for sustainability\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question - Submitted to the hybrid / multi-vector search\n",
    "result = rag_chain_hybrid.invoke(user_query)\n",
    "retrieved_docs = result[\"context\"]\n",
    "\n",
    "print(f\"Original Question to Dense Search: {user_query}\\n\")\n",
    "print(f\"Relevance Score: {result['answer']['relevance_score']}\\n\")\n",
    "print(f\"Final Answer:\\n{result['answer']['final_answer']}\\n\\n\")\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(\n",
    "        f\"Document {i}: Document ID: {doc.metadata['id']} source: {doc.metadata['source']}\"\n",
    "    )\n",
    "    print(f\"Content:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHETIC DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator with openai models\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm, critic_llm, embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m query_distribution \u001b[38;5;241m=\u001b[39m default_query_distribution(LangchainLLMWrapper(generator_llm))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#### FOR FOLLOWING CODE: Uncomment and run once to generate source for test dataset! ####\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# generate testset -\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/ragas/testset/synthesizers/generate.py:185\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[0m\n\u001b[1;32m    182\u001b[0m kg \u001b[38;5;241m=\u001b[39m KnowledgeGraph(nodes\u001b[38;5;241m=\u001b[39mnodes)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# apply transforms and update the knowledge graph\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mapply_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknowledge_graph \u001b[38;5;241m=\u001b[39m kg\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    189\u001b[0m     testset_size\u001b[38;5;241m=\u001b[39mtestset_size,\n\u001b[1;32m    190\u001b[0m     query_distribution\u001b[38;5;241m=\u001b[39mquery_distribution,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m     raise_exceptions\u001b[38;5;241m=\u001b[39mraise_exceptions,\n\u001b[1;32m    195\u001b[0m )\n",
      "File \u001b[0;32m/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/ragas/testset/transforms/engine.py:106\u001b[0m, in \u001b[0;36mapply_transforms\u001b[0;34m(kg, transforms, run_config, callbacks)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transforms, t\u001b[38;5;241m.\u001b[39mList):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[0;32m--> 106\u001b[0m         \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_coroutines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_execution_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[43mget_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# if Parallel, collect inside it and run it all\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transforms, Parallel):\n",
      "File \u001b[0;32m/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a list of Document objects from the chunks\n",
    "documents = [Document(page_content=chunk) for chunk in splits]\n",
    "\n",
    "query_distribution = default_query_distribution(LangchainLLMWrapper(generator_llm))\n",
    "\n",
    "\n",
    "#### FOR FOLLOWING CODE: Uncomment and run once to generate source for test dataset! ####\n",
    "# generate testset -\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    testset_size=10,\n",
    "    query_distribution=query_distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison dataframe\n",
    "testset_df = testset.to_pandas()\n",
    "\n",
    "# save dataframes to CSV files in the specified directory\n",
    "testset_df.to_csv(os.path.join(\"./data/testset_data.csv\"), index=False)\n",
    "\n",
    "print(\"testset DataFrame saved successfully in the local directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset DataFrame loaded successfully from local directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Google prioritize the human experience...</td>\n",
       "      <td>['Moving ahead, we’ll continue to build partne...</td>\n",
       "      <td>Google prioritized the human experience and co...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the climate-conscious data center coo...</td>\n",
       "      <td>['In 2022, we described our climate-conscious ...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Google aim to promote sustainability ...</td>\n",
       "      <td>['that Google can make a meaningful difference...</td>\n",
       "      <td>Google aims to promote sustainability through ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Google's involvement in the iMasons Cl...</td>\n",
       "      <td>['iMasons Climate AccordGoogle is a founding m...</td>\n",
       "      <td>Google is a founding member and part of the go...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the impact of the Rødby solar farm in ...</td>\n",
       "      <td>['0246\\n2.49Scope 2 emissions \\n(million tCO2e...</td>\n",
       "      <td>The impact of the Rødby solar farm in Denmark ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How did Google prioritize the human experience...   \n",
       "1  How does the climate-conscious data center coo...   \n",
       "2  How does Google aim to promote sustainability ...   \n",
       "3  What is Google's involvement in the iMasons Cl...   \n",
       "4  What is the impact of the Rødby solar farm in ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['Moving ahead, we’ll continue to build partne...   \n",
       "1  ['In 2022, we described our climate-conscious ...   \n",
       "2  ['that Google can make a meaningful difference...   \n",
       "3  ['iMasons Climate AccordGoogle is a founding m...   \n",
       "4  ['0246\\n2.49Scope 2 emissions \\n(million tCO2e...   \n",
       "\n",
       "                                        ground_truth evolution_type metadata  \\\n",
       "0  Google prioritized the human experience and co...         simple     [{}]   \n",
       "1  The climate-conscious data center cooling stra...         simple     [{}]   \n",
       "2  Google aims to promote sustainability through ...         simple     [{}]   \n",
       "3  Google is a founding member and part of the go...         simple     [{}]   \n",
       "4  The impact of the Rødby solar farm in Denmark ...         simple     [{}]   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data from saved testset, rather than generating above\n",
    "### load dataframs from CSV file\n",
    "saved_testset_df = pd.read_csv(os.path.join(\"./data/testset_data.csv\"))\n",
    "print(\"testset DataFrame loaded successfully from local directory.\")\n",
    "saved_testset_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE SIMILARITY SEARCH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a dictionary\n",
    "saved_testing_data = saved_testset_df.astype(str).to_dict(orient=\"list\")\n",
    "\n",
    "# Create the testing_dataset\n",
    "saved_testing_dataset = Dataset.from_dict(saved_testing_data)\n",
    "\n",
    "# Update the testing_dataset to include only these columns -\n",
    "# \"question\", \"ground_truth\", \"answer\", \"contexts\"\n",
    "saved_testing_dataset_sm = saved_testing_dataset.remove_columns(\n",
    "    [\"evolution_type\", \"episode_done\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'metadata'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_testing_dataset_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL SETS FOR EACH CHAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate answers using the RAG chain\n",
    "def generate_answer(question, ground_truth, rag_chain):\n",
    "    result = rag_chain.invoke(question)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": result[\"answer\"][\"final_answer\"],\n",
    "        \"contexts\": [doc.page_content for doc in result[\"context\"]],\n",
    "        \"ground_truth\": ground_truth,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x72bfb3c30a60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:19<00:00,  1.99s/ examples]\n"
     ]
    }
   ],
   "source": [
    "# Add the \"question\", \"answer\", \"contexts\", and \"ground_truth\" to the testing_dataset\n",
    "testing_dataset_similarity = saved_testing_dataset_sm.map(\n",
    "    lambda x: generate_answer(x[\"question\"], x[\"ground_truth\"], rag_chain_similarity),\n",
    "    remove_columns=saved_testing_dataset_sm.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Exception raised in Job[7]: ResponseError({})\n",
      "Evaluating:   2%|▏         | 1/60 [01:55<1:53:28, 115.40s/it]Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Evaluating:   3%|▎         | 2/60 [03:00<1:22:42, 85.56s/it] Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Evaluating:  28%|██▊       | 17/60 [03:34<06:03,  8.44s/it] Exception raised in Job[31]: AttributeError('StringIO' object has no attribute 'question')\n",
      "Evaluating:  33%|███▎      | 20/60 [03:40<04:42,  7.07s/it]Exception raised in Job[16]: TimeoutError()\n",
      "Evaluating:  35%|███▌      | 21/60 [04:55<08:35, 13.21s/it]Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Evaluating:  37%|███▋      | 22/60 [06:00<12:06, 19.12s/it]Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Evaluating:  55%|█████▌    | 33/60 [06:34<03:59,  8.86s/it]Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Evaluating:  60%|██████    | 36/60 [06:38<02:56,  7.35s/it]/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/ragas/metrics/_answer_similarity.py:87: RuntimeWarning: invalid value encountered in divide\n",
      "  embedding_1_normalized = embedding_1 / norms_1\n",
      "/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/ragas/metrics/_answer_similarity.py:87: RuntimeWarning: invalid value encountered in divide\n",
      "  embedding_1_normalized = embedding_1 / norms_1\n",
      "Evaluating:  63%|██████▎   | 38/60 [06:39<02:15,  6.18s/it]Exception raised in Job[49]: ResponseError({})\n",
      "Evaluating:  65%|██████▌   | 39/60 [06:56<02:34,  7.37s/it]Exception raised in Job[37]: AttributeError('StringIO' object has no attribute 'question')\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt context_recall_classification_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[45]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Evaluating:  68%|██████▊   | 41/60 [07:16<02:31,  7.95s/it]Exception raised in Job[36]: TimeoutError()\n",
      "Evaluating:  70%|███████   | 42/60 [07:55<03:40, 12.25s/it]Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Evaluating:  72%|███████▏  | 43/60 [09:00<05:56, 20.98s/it]Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Evaluating:  83%|████████▎ | 50/60 [09:35<01:49, 10.98s/it]Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Evaluating:  87%|████████▋ | 52/60 [09:38<01:13,  9.15s/it]Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Evaluating:  90%|█████████ | 54/60 [09:39<00:42,  7.11s/it]Exception raised in Job[54]: TimeoutError()\n",
      "Evaluating:  92%|█████████▏| 55/60 [09:56<00:42,  8.59s/it]Exception raised in Job[55]: TimeoutError()\n",
      "/mnt/kalista/git-cuongpiger/langchain-labs/.venv/lib/python3.10/site-packages/ragas/metrics/_answer_similarity.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  embedding_2_normalized = embedding_2 / norms_2\n",
      "Evaluating:  95%|█████████▌| 57/60 [10:11<00:24,  8.17s/it]Exception raised in Job[56]: TimeoutError()\n",
      "Evaluating:  97%|█████████▋| 58/60 [10:16<00:15,  7.73s/it]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt context_recall_classification_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[57]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Evaluating: 100%|██████████| 60/60 [10:26<00:00, 10.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Google prioritize the human experience...</td>\n",
       "      <td>[Given the scale of the problem, innovation  w...</td>\n",
       "      <td>To answer your question about how Google prior...</td>\n",
       "      <td>Google prioritized the human experience and co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the climate-conscious data center coo...</td>\n",
       "      <td>[Given the scale of the problem, innovation  w...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Google aim to promote sustainability ...</td>\n",
       "      <td>[Given the scale of the problem, innovation  w...</td>\n",
       "      <td>Google aims to promote sustainability through ...</td>\n",
       "      <td>Google aims to promote sustainability through ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Google's involvement in the iMasons Cl...</td>\n",
       "      <td>[CDP  (formerly \\nknown as the Carbon Disclosu...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>Google is a founding member and part of the go...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the impact of the Rødby solar farm in ...</td>\n",
       "      <td>[CDP  (formerly \\nknown as the Carbon Disclosu...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>The impact of the Rødby solar farm in Denmark ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How did Google work with CSIRO and Kaggle on a...</td>\n",
       "      <td>[Given the scale of the problem, innovation  w...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>Google collaborated with the Commonwealth Scie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What's the recycled aluminum percentage in new...</td>\n",
       "      <td>[Given the scale of the problem, innovation  w...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>Recycled aluminum in the enclosures of new Goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has Google worked with BEF to support wate...</td>\n",
       "      <td>[CDP  (formerly \\nknown as the Carbon Disclosu...</td>\n",
       "      <td>I don't know the specific details about Google...</td>\n",
       "      <td>Google has partnered closely with Bonneville E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What environmental data does an independent au...</td>\n",
       "      <td>[We respect the independence and agency of tra...</td>\n",
       "      <td>Based on the provided context, an independent ...</td>\n",
       "      <td>An independent auditor reviews select environm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How many Olympic-sized swimming pools are equi...</td>\n",
       "      <td>[AI for sustainability\\nSeven years into our j...</td>\n",
       "      <td>To calculate how many Olympic-sized swimming p...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  How did Google prioritize the human experience...   \n",
       "1  How does the climate-conscious data center coo...   \n",
       "2  How does Google aim to promote sustainability ...   \n",
       "3  What is Google's involvement in the iMasons Cl...   \n",
       "4  What is the impact of the Rødby solar farm in ...   \n",
       "5  How did Google work with CSIRO and Kaggle on a...   \n",
       "6  What's the recycled aluminum percentage in new...   \n",
       "7  How has Google worked with BEF to support wate...   \n",
       "8  What environmental data does an independent au...   \n",
       "9  How many Olympic-sized swimming pools are equi...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Given the scale of the problem, innovation  w...   \n",
       "1  [Given the scale of the problem, innovation  w...   \n",
       "2  [Given the scale of the problem, innovation  w...   \n",
       "3  [CDP  (formerly \\nknown as the Carbon Disclosu...   \n",
       "4  [CDP  (formerly \\nknown as the Carbon Disclosu...   \n",
       "5  [Given the scale of the problem, innovation  w...   \n",
       "6  [Given the scale of the problem, innovation  w...   \n",
       "7  [CDP  (formerly \\nknown as the Carbon Disclosu...   \n",
       "8  [We respect the independence and agency of tra...   \n",
       "9  [AI for sustainability\\nSeven years into our j...   \n",
       "\n",
       "                                            response  \\\n",
       "0  To answer your question about how Google prior...   \n",
       "1  The climate-conscious data center cooling stra...   \n",
       "2  Google aims to promote sustainability through ...   \n",
       "3                                      I don't know.   \n",
       "4                                      I don't know.   \n",
       "5                                      I don't know.   \n",
       "6                                      I don't know.   \n",
       "7  I don't know the specific details about Google...   \n",
       "8  Based on the provided context, an independent ...   \n",
       "9  To calculate how many Olympic-sized swimming p...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  Google prioritized the human experience and co...           NaN   \n",
       "1  The climate-conscious data center cooling stra...           NaN   \n",
       "2  Google aims to promote sustainability through ...           NaN   \n",
       "3  Google is a founding member and part of the go...           NaN   \n",
       "4  The impact of the Rødby solar farm in Denmark ...           NaN   \n",
       "5  Google collaborated with the Commonwealth Scie...           NaN   \n",
       "6  Recycled aluminum in the enclosures of new Goo...           NaN   \n",
       "7  Google has partnered closely with Bonneville E...           NaN   \n",
       "8  An independent auditor reviews select environm...           NaN   \n",
       "9  The answer to given question is not present in...           NaN   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  answer_correctness  \\\n",
       "0               NaN                NaN             NaN                 NaN   \n",
       "1               NaN                NaN             NaN                 NaN   \n",
       "2               NaN                NaN             NaN                 NaN   \n",
       "3               NaN                NaN             NaN                 NaN   \n",
       "4               NaN                NaN             NaN                 NaN   \n",
       "5               NaN                NaN             NaN                 NaN   \n",
       "6               NaN                NaN             NaN                 NaN   \n",
       "7               NaN                NaN             NaN                 NaN   \n",
       "8               NaN                NaN             NaN                 NaN   \n",
       "9               NaN                NaN             NaN            0.818011   \n",
       "\n",
       "   semantic_similarity  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2             0.541176  \n",
       "3             0.283941  \n",
       "4             0.550190  \n",
       "5                  NaN  \n",
       "6             0.354894  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity search score\n",
    "score_similarity = evaluate(\n",
    "    testing_dataset_similarity,\n",
    "    llm=critic_llm,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "        answer_similarity,\n",
    "    ],\n",
    "    embeddings=critic_llm_embedding,\n",
    ")\n",
    "similarity_df = score_similarity.to_pandas()\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
