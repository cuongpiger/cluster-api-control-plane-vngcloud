{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import List, Optional, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Google credentials\n",
    "\n",
    "- **NOTE**: Remember change the `GOOGLE_APPLICATION_CREDENTIALS` to the path of your own Google credentials file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    \"/home/cuongdm/git-cuongpiger/secret/work/vngcloud/ai-platform/vertex-ai-credential.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatVertexAI(temperature=0, model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Xin ch√†o T·ª©! R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n. üòÑ B·∫°n mu·ªën l√†m g√¨ h√¥m nay? \\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.028007585555315018, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.05184546485543251}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.020964214578270912, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.04023800417780876}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08389048278331757, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.06187598779797554}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.16344575583934784, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.19682610034942627}], 'usage_metadata': {'prompt_token_count': 7, 'candidates_token_count': 22, 'total_token_count': 29, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.1763361692428589}, id='run-f07e399a-336c-4626-9766-60a494105482-0', usage_metadata={'input_tokens': 7, 'output_tokens': 22, 'total_tokens': 29})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Xin ch√†o, tao l√† T·ª©\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='B·∫°n mu·ªën n√≥i ra h·∫øt t·∫•t c·∫£ thay v√¨ g√¨? \\n\\nH√£y chia s·∫ª v·ªõi t√¥i nh·ªØng g√¨ b·∫°n ƒëang nghƒ©. T√¥i ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe v√† h·ªó tr·ª£ b·∫°n. \\n\\nC√≥ th·ªÉ b·∫°n ƒëang mu·ªën:\\n\\n* **N√≥i ra nh·ªØng c·∫£m x√∫c b·ªã k√¨m n√©n:** B·∫°n c√≥ th·ªÉ ƒëang gi·ªØ trong l√≤ng nh·ªØng c·∫£m x√∫c ti√™u c·ª±c nh∆∞ t·ª©c gi·∫≠n, bu·ªìn b√£, th·∫•t v·ªçng, hay s·ª£ h√£i. N√≥i ra ch√∫ng c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i t·ªèa v√† c·∫£m th·∫•y nh·∫π nh√†ng h∆°n.\\n* **Chia s·∫ª nh·ªØng suy nghƒ© v√† √Ω t∆∞·ªüng:** B·∫°n c√≥ th·ªÉ c√≥ nh·ªØng √Ω t∆∞·ªüng hay nh·ªØng suy nghƒ© ƒë·ªôc ƒë√°o m√† b·∫°n mu·ªën chia s·∫ª v·ªõi ng∆∞·ªùi kh√°c. N√≥i ra ch√∫ng c√≥ th·ªÉ gi√∫p b·∫°n nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi v√† s·ª± h·ªó tr·ª£.\\n* **Gi·∫£i quy·∫øt m·ªôt v·∫•n ƒë·ªÅ:** B·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i m·ªôt v·∫•n ƒë·ªÅ kh√≥ khƒÉn v√† mu·ªën t√¨m c√°ch gi·∫£i quy·∫øt. N√≥i ra v·∫•n ƒë·ªÅ c·ªßa b·∫°n c√≥ th·ªÉ gi√∫p b·∫°n nh·∫≠n ƒë∆∞·ª£c l·ªùi khuy√™n v√† s·ª± gi√∫p ƒë·ª° t·ª´ ng∆∞·ªùi kh√°c.\\n\\nD√π b·∫°n mu·ªën n√≥i ra ƒëi·ªÅu g√¨, h√£y nh·ªõ r·∫±ng b·∫°n kh√¥ng c√¥ ƒë∆°n. T√¥i ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe v√† h·ªó tr·ª£ b·∫°n. \\n\\nH√£y chia s·∫ª v·ªõi t√¥i nh·ªØng g√¨ b·∫°n ƒëang nghƒ©, t√¥i s·∫Ω c·ªë g·∫Øng h·∫øt s·ª©c ƒë·ªÉ gi√∫p b·∫°n. \\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.018833156675100327, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.007577236276119947}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.004070146940648556, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.01826431415975094}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.03258975222706795, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.010328171774744987}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.03021467849612236, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.04272221028804779}], 'usage_metadata': {'prompt_token_count': 15, 'candidates_token_count': 260, 'total_token_count': 275, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.20935795123760517}, id='run-aa0c7712-84f8-4216-aaba-7fe605f3097e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 260, 'total_tokens': 275})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [HumanMessage(content=\"Nhi·ªÅu khi tao mu·ªën m·ªôt l·∫ßn n√≥i ra h·∫øt t·∫•t c·∫£ thay v√¨.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='VKS (VngCloud Kubernetes Service) cung c·∫•p nhi·ªÅu t√≠nh nƒÉng h·ªØu √≠ch cho vi·ªác tri·ªÉn khai v√† qu·∫£n l√Ω ·ª©ng d·ª•ng tr√™n Kubernetes, bao g·ªìm:\\n\\n**Qu·∫£n l√Ω c·ª•m Kubernetes:**\\n\\n* **Fully managed Kubernetes:** VKS t·ª± ƒë·ªông qu·∫£n l√Ω v√† c·∫≠p nh·∫≠t c√°c th√†nh ph·∫ßn c·ªßa c·ª•m Kubernetes, gi√∫p b·∫°n t·∫≠p trung v√†o vi·ªác ph√°t tri·ªÉn ·ª©ng d·ª•ng.\\n* **Autoscaling:** T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc c·ª•m Kubernetes d·ª±a tr√™n t·∫£i tr·ªçng c·ªßa ·ª©ng d·ª•ng, ƒë·∫£m b·∫£o hi·ªáu su·∫•t v√† t·ªëi ∆∞u h√≥a chi ph√≠.\\n* **Monitoring:** Theo d√µi tr·∫°ng th√°i v√† hi·ªáu su·∫•t c·ªßa c·ª•m Kubernetes, gi√∫p b·∫°n ph√°t hi·ªán v√† gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªãp th·ªùi.\\n* **Logging:** Thu th·∫≠p v√† l∆∞u tr·ªØ nh·∫≠t k√Ω c·ªßa c·ª•m Kubernetes, gi√∫p b·∫°n ph√¢n t√≠ch v√† g·ª° l·ªói ·ª©ng d·ª•ng.\\n* **Networking:** Cung c·∫•p c√°c d·ªãch v·ª• m·∫°ng cho c·ª•m Kubernetes, bao g·ªìm load balancing, DNS, v√† ingress controller.\\n* **Security:** B·∫£o m·∫≠t c·ª•m Kubernetes b·∫±ng c√°c t√≠nh nƒÉng nh∆∞ RBAC, network policy, v√† container security.\\n\\n**Ph√°t tri·ªÉn v√† tri·ªÉn khai ·ª©ng d·ª•ng:**\\n\\n* **Deployment:** Tri·ªÉn khai ·ª©ng d·ª•ng l√™n c·ª•m Kubernetes m·ªôt c√°ch d·ªÖ d√†ng v√† nhanh ch√≥ng.\\n* **Service discovery:** Ph√°t hi·ªán v√† k·∫øt n·ªëi c√°c d·ªãch v·ª• trong c·ª•m Kubernetes.\\n* **Configuration management:** Qu·∫£n l√Ω c·∫•u h√¨nh c·ªßa ·ª©ng d·ª•ng m·ªôt c√°ch t·∫≠p trung.\\n* **CI/CD integration:** T√≠ch h·ª£p v·ªõi c√°c c√¥ng c·ª• CI/CD ƒë·ªÉ t·ª± ƒë·ªông h√≥a qu√° tr√¨nh ph√°t tri·ªÉn v√† tri·ªÉn khai ·ª©ng d·ª•ng.\\n\\n**Ngo√†i ra, VKS c√≤n cung c·∫•p c√°c t√≠nh nƒÉng kh√°c nh∆∞:**\\n\\n* **Backup and restore:** Sao l∆∞u v√† kh√¥i ph·ª•c d·ªØ li·ªáu c·ªßa c·ª•m Kubernetes.\\n* **Disaster recovery:** Kh√¥i ph·ª•c c·ª•m Kubernetes sau khi x·∫£y ra s·ª± c·ªë.\\n* **Support:** H·ªó tr·ª£ k·ªπ thu·∫≠t t·ª´ VngCloud.\\n\\nVKS l√† m·ªôt gi·∫£i ph√°p to√†n di·ªán cho vi·ªác tri·ªÉn khai v√† qu·∫£n l√Ω ·ª©ng d·ª•ng tr√™n Kubernetes, gi√∫p b·∫°n ti·∫øt ki·ªám th·ªùi gian, c√¥ng s·ª©c v√† chi ph√≠.\\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0128211984410882, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.01590641401708126}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.013222835958003998, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1613202542066574}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.011331766843795776, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.02887095883488655}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0039454116486012936, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.02194826677441597}], 'usage_metadata': {'prompt_token_count': 69, 'candidates_token_count': 431, 'total_token_count': 500, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.1590819392016205}, id='run-57db8166-b3a3-4baa-85f1-41d4bff7adf8-0', usage_metadata={'input_tokens': 69, 'output_tokens': 431, 'total_tokens': 500})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"VKS l√† g√¨?\"),\n",
    "        AIMessage(\n",
    "            content=\"VKS l√† vi·∫øt t·∫Øt c·ªßa VngCloud Kubernetes Service, m·ªôt d·ªãch v·ª• c·ªßa VngCloud nh·∫±m cung c·∫•p c√°c c·ª•m Kubernetes ƒë·∫øn kh√°ch h√†ng. VKS cung c·∫•p c√°c t√≠nh nƒÉng nh∆∞ fully managed Kubernetes, autoscaling, monitoring, logging, v√† nhi·ªÅu t√≠nh nƒÉng kh√°c.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"C√°c t√≠nh nƒÉng c·ªßa VKS l√† g√¨?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "B·∫°n kh√¥ng th·ªÉ d·∫°y m·ªôt con c√° bi·∫øt leo c√¢y! C√° ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ s·ªëng d∆∞·ªõi n∆∞·ªõc, ch√∫ng c√≥ mang ƒë·ªÉ th·ªü v√† v√¢y ƒë·ªÉ b∆°i. Ch√∫ng kh√¥ng c√≥ ch√¢n, tay, hay kh·∫£ nƒÉng leo tr√®o. \n",
      "\n",
      "C√¢u h·ªèi n√†y l√† m·ªôt c√¢u ƒë·ªë vui, nh·∫±m nh·∫Øc nh·ªü ch√∫ng ta r·∫±ng m·ªói lo√†i ƒë·ªông v·∫≠t ƒë·ªÅu c√≥ nh·ªØng kh·∫£ nƒÉng v√† gi·ªõi h·∫°n ri√™ng.\n"
     ]
    }
   ],
   "source": [
    "query = \"L√†m sao ƒë·ªÉ d·∫°y m·ªôt con c√° bi·∫øt leo c√¢y?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "B·∫°n kh√¥ng th·ªÉ d·∫°y m·ªôt con c√° bi·∫øt leo c√¢y! C√° ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ s·ªëng d∆∞·ªõi n∆∞·ªõc, ch√∫ng c√≥ mang ƒë·ªÉ th·ªü v√† v√¢y ƒë·ªÉ b∆°i. Ch√∫ng kh√¥ng c√≥ ch√¢n, tay, hay kh·∫£ nƒÉng leo tr√®o. \n",
      "\n",
      "C√¢u h·ªèi n√†y l√† m·ªôt c√¢u ƒë·ªë vui, nh·∫±m nh·∫Øc nh·ªü ch√∫ng ta r·∫±ng m·ªói lo√†i ƒë·ªông v·∫≠t ƒë·ªÅu c√≥ nh·ªØng kh·∫£ nƒÉng v√† gi·ªõi h·∫°n ri√™ng.\n"
     ]
    }
   ],
   "source": [
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o. H√£y tr·∫£ l·ªùi c√°c c√¢u h·ªèi b·∫±ng h·∫øt kh·∫£ nƒÉng c·ªßa b·∫°n b·∫±ng Ti·∫øng Vi·ªát.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Chia tay l√† ƒëi·ªÅu kh√¥ng ai mu·ªën, nh·∫•t l√† khi n√≥ khi·∫øn ng∆∞·ªùi kia t·ªïn th∆∞∆°ng. D√π b·∫°n ƒë√£ h·∫øt y√™u, vi·ªác n√≥i l·ªùi chia tay v·∫´n c·∫ßn s·ª± t·∫ø nh·ªã v√† t√¥n tr·ªçng. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë c√°ch ƒë·ªÉ gi·∫£m thi·ªÉu t·ªïn th∆∞∆°ng cho ƒë·ªëi ph∆∞∆°ng:\n",
      "\n",
      "**1. Ch·ªçn th·ªùi ƒëi·ªÉm v√† ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p:**\n",
      "\n",
      "* **Tr√°nh chia tay qua tin nh·∫Øn, ƒëi·ªán tho·∫°i:** H√£y d√†nh th·ªùi gian g·∫∑p m·∫∑t tr·ª±c ti·∫øp ƒë·ªÉ th·ªÉ hi·ªán s·ª± t√¥n tr·ªçng v√† cho ph√©p ƒë·ªëi ph∆∞∆°ng ƒë∆∞·ª£c nh√¨n th·∫•y c·∫£m x√∫c c·ªßa b·∫°n.\n",
      "* **Ch·ªçn n∆°i ri√™ng t∆∞:** N∆°i y√™n tƒ©nh, kh√¥ng c√≥ ng∆∞·ªùi xung quanh s·∫Ω gi√∫p c·∫£ hai tho·∫£i m√°i chia s·∫ª c·∫£m x√∫c.\n",
      "\n",
      "**2. N√≥i r√µ r√†ng v√† ch√¢n th√†nh:**\n",
      "\n",
      "* **Tr√°nh v√≤ng vo, √∫p m·ªü:** H√£y th·∫≥ng th·∫Øn n√≥i r·∫±ng b·∫°n ƒë√£ h·∫øt y√™u v√† mu·ªën chia tay.\n",
      "* **Gi·∫£i th√≠ch l√Ω do m·ªôt c√°ch ng·∫Øn g·ªçn:** Kh√¥ng c·∫ßn ph·∫£i ƒëi s√¢u v√†o chi ti·∫øt, ch·ªâ c·∫ßn gi·∫£i th√≠ch ƒë·ªß ƒë·ªÉ ƒë·ªëi ph∆∞∆°ng hi·ªÉu.\n",
      "* **Th·ªÉ hi·ªán s·ª± t√¥n tr·ªçng:** N√≥i l·ªùi c·∫£m ∆°n ƒë·ªëi ph∆∞∆°ng v√¨ nh·ªØng g√¨ h·ªç ƒë√£ d√†nh cho b·∫°n.\n",
      "\n",
      "**3. Tr√°nh ƒë·ªï l·ªói:**\n",
      "\n",
      "* **T·∫≠p trung v√†o c·∫£m x√∫c c·ªßa b·∫°n:** Thay v√¨ n√≥i \"Em kh√¥ng c√≤n y√™u anh n·ªØa\" h√£y n√≥i \"Em c·∫£m th·∫•y t√¨nh c·∫£m c·ªßa ch√∫ng ta ƒë√£ thay ƒë·ªïi\".\n",
      "* **Kh√¥ng ƒë·ªï l·ªói cho ƒë·ªëi ph∆∞∆°ng:** H√£y nh·∫≠n tr√°ch nhi·ªám cho quy·∫øt ƒë·ªãnh c·ªßa m√¨nh.\n",
      "\n",
      "**4. Chu·∫©n b·ªã t√¢m l√Ω cho ph·∫£n ·ª©ng c·ªßa ƒë·ªëi ph∆∞∆°ng:**\n",
      "\n",
      "* **H√£y ki√™n nh·∫´n:** ƒê·ªëi ph∆∞∆°ng c√≥ th·ªÉ bu·ªìn, gi·∫≠n d·ªØ ho·∫∑c th·∫≠m ch√≠ l√† kh√¥ng mu·ªën nghe b·∫°n n√≥i. H√£y ki√™n nh·∫´n l·∫Øng nghe v√† cho h·ªç th·ªùi gian ƒë·ªÉ x·ª≠ l√Ω c·∫£m x√∫c.\n",
      "* **Kh√¥ng tranh c√£i:** H√£y gi·ªØ b√¨nh tƒ©nh v√† tr√°nh tranh c√£i.\n",
      "\n",
      "**5. Sau khi chia tay:**\n",
      "\n",
      "* **H√£y gi·ªØ kho·∫£ng c√°ch:** Cho c·∫£ hai th·ªùi gian ƒë·ªÉ b√¨nh tƒ©nh v√† suy nghƒ©.\n",
      "* **Tr√°nh li√™n l·∫°c:** Tr√°nh li√™n l·∫°c v·ªõi ƒë·ªëi ph∆∞∆°ng trong th·ªùi gian ƒë·∫ßu ƒë·ªÉ tr√°nh l√†m h·ªç th√™m ƒëau l√≤ng.\n",
      "\n",
      "**L∆∞u √Ω:**\n",
      "\n",
      "* Kh√¥ng c√≥ c√°ch n√†o ƒë·ªÉ chia tay m√† kh√¥ng khi·∫øn ƒë·ªëi ph∆∞∆°ng t·ªïn th∆∞∆°ng.\n",
      "* H√£y c·ªë g·∫Øng th·ªÉ hi·ªán s·ª± ƒë·ªìng c·∫£m v√† t√¥n tr·ªçng ƒë·ªëi ph∆∞∆°ng.\n",
      "* H√£y nh·ªõ r·∫±ng, chia tay l√† m·ªôt ph·∫ßn c·ªßa cu·ªôc s·ªëng v√† b·∫°n s·∫Ω v∆∞·ª£t qua ƒë∆∞·ª£c.\n",
      "\n",
      "**Ngo√†i ra, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m c√°c b√†i vi·∫øt v·ªÅ c√°ch chia tay m·ªôt c√°ch vƒÉn minh tr√™n m·∫°ng.**\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"N·∫øu mu·ªën n√≥i chia tay khi ƒë√£ h·∫øt y√™u, l√†m sao ƒë·ªÉ ƒë·ªëi ph∆∞∆°ng kh√¥ng t·ªïn th∆∞∆°ng? (Vui l√≤ng tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ti·∫øng anh tao ngu l·∫Øm)\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "B√†i h√°t \"Em c·ªßa ng√†y h√¥m qua\" c·ªßa S∆°n T√πng MTP k·ªÉ v·ªÅ m·ªôt m·ªëi t√¨nh ƒë√£ qua, m·ªôt t√¨nh y√™u ƒë·∫πp nh∆∞ng kh√¥ng th·ªÉ gi·ªØ ƒë∆∞·ª£c. Ca kh√∫c th·ªÉ hi·ªán n·ªói nh·ªõ nhung, ti·∫øc nu·ªëi v√† s·ª± day d·ª©t c·ªßa ng∆∞·ªùi con trai khi ph·∫£i chia tay ng∆∞·ªùi y√™u. \n",
      "\n",
      "**N·ªôi dung ch√≠nh:**\n",
      "\n",
      "* **N·ªói nh·ªõ nhung:** Anh nh·ªõ v·ªÅ nh·ªØng k·ª∑ ni·ªám ƒë·∫πp c·ªßa hai ng∆∞·ªùi, nh·ªØng l·ªùi h·ª©a h·∫πn, nh·ªØng kho·∫£nh kh·∫Øc ng·ªçt ng√†o.\n",
      "* **S·ª± ti·∫øc nu·ªëi:** Anh ti·∫øc nu·ªëi v√¨ ƒë√£ kh√¥ng gi·ªØ ƒë∆∞·ª£c t√¨nh y√™u, v√¨ ƒë√£ ƒë·ªÉ em ra ƒëi.\n",
      "* **S·ª± day d·ª©t:** Anh day d·ª©t v√¨ nh·ªØng l·ªói l·∫ßm trong qu√° kh·ª©, nh·ªØng ƒëi·ªÅu anh ƒë√£ l√†m sai khi·∫øn em ph·∫£i r·ªùi xa.\n",
      "* **S·ª± hi v·ªçng:** D√π bi·∫øt r·∫±ng em ƒë√£ l√† qu√° kh·ª©, nh∆∞ng anh v·∫´n hy v·ªçng m·ªôt ng√†y n√†o ƒë√≥ s·∫Ω g·∫∑p l·∫°i em.\n",
      "\n",
      "**Th√¥ng ƒëi·ªáp:**\n",
      "\n",
      "B√†i h√°t l√† l·ªùi t·ª± s·ª± c·ªßa m·ªôt ng∆∞·ªùi ƒë√†n √¥ng ƒëang ch√¨m ƒë·∫Øm trong n·ªói nh·ªõ nhung v√† ti·∫øc nu·ªëi v·ªÅ m·ªôt t√¨nh y√™u ƒë√£ qua. N√≥ nh·∫Øc nh·ªü ch√∫ng ta v·ªÅ gi√° tr·ªã c·ªßa t√¨nh y√™u v√† s·ª± quan tr·ªçng c·ªßa vi·ªác tr√¢n tr·ªçng nh·ªØng g√¨ m√¨nh ƒëang c√≥.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"H√£y t√≥m g·ªçn n·ªôi dung b√†i h√°t Em c·ªßa ng√†y h√¥m qua c·ªßa S∆°n T√πng MTP\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "C√¢u h·ªèi b·∫°n v·ª´a h·ªèi t√¥i l√†: \"H√£y t√≥m g·ªçn n·ªôi dung b√†i h√°t Em c·ªßa ng√†y h√¥m qua c·ªßa S∆°n T√πng MTP\".\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"C√¢u h·ªèi m√† t√¥i v·ª´a h·ªèi b·∫°n l√† g√¨ v·∫≠y\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "M√¨nh hi·ªÉu b·∫°n ƒëang mu·ªën chia tay nh∆∞ng kh√¥ng mu·ªën l√† ng∆∞·ªùi tr·ª±c ti·∫øp n√≥i ra. ƒê√¢y l√† m·ªôt t√¨nh hu·ªëng kh√≥ x·ª≠, nh∆∞ng m√¨nh c√≥ th·ªÉ ƒë∆∞a ra m·ªôt s·ªë g·ª£i √Ω:\n",
      "\n",
      "* **N√≥i r√µ r√†ng v·ªÅ c·∫£m x√∫c c·ªßa b·∫°n:** H√£y chia s·∫ª v·ªõi ƒë·ªëi ph∆∞∆°ng r·∫±ng b·∫°n c·∫£m th·∫•y m·ªëi quan h·ªá kh√¥ng c√≤n ph√π h·ª£p n·ªØa, b·∫°n kh√¥ng c√≤n h·∫°nh ph√∫c nh∆∞ tr∆∞·ªõc. H√£y t·∫≠p trung v√†o c·∫£m x√∫c c·ªßa b·∫°n, tr√°nh ƒë·ªï l·ªói cho ƒë·ªëi ph∆∞∆°ng.\n",
      "* **T·∫°o kho·∫£ng c√°ch:** H√£y gi·∫£m thi·ªÉu th·ªùi gian g·∫∑p m·∫∑t, nh·∫Øn tin, g·ªçi ƒëi·ªán cho ƒë·ªëi ph∆∞∆°ng. ƒêi·ªÅu n√†y s·∫Ω khi·∫øn h·ªç nh·∫≠n ra s·ª± thay ƒë·ªïi trong m·ªëi quan h·ªá v√† t·ª± ƒë·∫∑t c√¢u h·ªèi.\n",
      "* **N√≥i v·ªÅ t∆∞∆°ng lai:** H√£y chia s·∫ª v·ªõi ƒë·ªëi ph∆∞∆°ng v·ªÅ nh·ªØng d·ª± ƒë·ªãnh c·ªßa b·∫°n trong t∆∞∆°ng lai, nh·ªØng ƒëi·ªÅu b·∫°n mu·ªën theo ƒëu·ªïi, v√† cho h·ªç th·∫•y r·∫±ng nh·ªØng d·ª± ƒë·ªãnh ƒë√≥ kh√¥ng c√≤n ph√π h·ª£p v·ªõi m·ªëi quan h·ªá hi·ªán t·∫°i.\n",
      "* **ƒê·ªÉ h·ªç t·ª± ƒë∆∞a ra quy·∫øt ƒë·ªãnh:** H√£y cho ƒë·ªëi ph∆∞∆°ng th·ªùi gian ƒë·ªÉ suy nghƒ© v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh. ƒê·ª´ng √©p bu·ªôc h·ªç ph·∫£i chia tay, h√£y ƒë·ªÉ h·ªç t·ª± nh·∫≠n ra r·∫±ng m·ªëi quan h·ªá n√†y kh√¥ng c√≤n ph√π h·ª£p n·ªØa.\n",
      "\n",
      "**L∆∞u √Ω:**\n",
      "\n",
      "* H√£y nh·ªõ r·∫±ng, vi·ªác chia tay l√† m·ªôt quy·∫øt ƒë·ªãnh kh√≥ khƒÉn ƒë·ªëi v·ªõi c·∫£ hai ng∆∞·ªùi. H√£y th·ªÉ hi·ªán s·ª± t√¥n tr·ªçng v√† c·∫£m th√¥ng v·ªõi ƒë·ªëi ph∆∞∆°ng.\n",
      "* H√£y chu·∫©n b·ªã t√¢m l√Ω cho nh·ªØng ph·∫£n ·ª©ng kh√°c nhau t·ª´ ƒë·ªëi ph∆∞∆°ng.\n",
      "* H√£y nh·ªõ r·∫±ng, b·∫°n c√≥ quy·ªÅn l·ª±a ch·ªçn h·∫°nh ph√∫c cho b·∫£n th√¢n.\n",
      "\n",
      "Ch√∫c b·∫°n m·∫°nh m·∫Ω v√† t√¨m ƒë∆∞·ª£c gi·∫£i ph√°p ph√π h·ª£p nh·∫•t cho m√¨nh!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"L√†m sao ƒë·ªÉ n√≥i chia tay nh∆∞ng ƒë·ªëi ph∆∞∆°ng ph·∫£i l√† ng∆∞·ªùi ch·ªß ƒë·ªông n√≥i\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=1000,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o\"),\n",
    "    HumanMessage(content=\"Ch√†o m√†y, tao l√† C∆∞·ªùng\"),\n",
    "    AIMessage(content=\"Ch√†o b·∫°n.\"),\n",
    "    HumanMessage(content=\"Cho tao bi·∫øt, VKS l√† g√¨ v·∫≠y?\"),\n",
    "    AIMessage(\n",
    "        content=\"VKS l√† vi·∫øt t·∫Øt c·ªßa VngCloud Kubernetes Service, m·ªôt d·ªãch v·ª• c·ªßa VngCloud nh·∫±m cung c·∫•p c√°c c·ª•m Kubernetes ƒë·∫øn kh√°ch h√†ng. VKS cung c·∫•p c√°c t√≠nh nƒÉng nh∆∞ fully managed Kubernetes, autoscaling, monitoring, logging, v√† nhi·ªÅu t√≠nh nƒÉng kh√°c.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"VKS c√≥ h·ªó tr·ª£ CSI kh√¥ng?\"),\n",
    "    AIMessage(\n",
    "        content=\"C√≥ ch·ª©, CSI l√† vi·∫øt t·∫Øt c·ªßa Container Storage Interface, m·ªôt chu·∫©n giao di·ªán cho ph√©p c√°c h·ªá th·ªëng l∆∞u tr·ªØ n·ªÅn t·∫£ng cung c·∫•p d·ªãch v·ª• l∆∞u tr·ªØ cho c√°c ·ª©ng d·ª•ng ch·∫°y tr√™n Kubernetes.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"L√†m sao ƒë·ªÉ t·∫°o m·ªôt PersistentVolumeClaim tr√™n VKS?\"),\n",
    "    AIMessage(\n",
    "        content=\"\"\"ƒê√¢y l√† m·ªôt v√≠ d·ª• ƒë·ªÉ t·∫°o m·ªôt PersistentVolumeClaim 20Gi tr√™n VKS\\n```yaml\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: my-expansion-storage-class                    # [1] The StorageClass name, CAN be changed\n",
    "provisioner: bs.csi.vngcloud.vn                       # The VNG-CLOUD CSI driver name\n",
    "parameters:\n",
    "  type: vtype-61c3fc5b-f4e9-45b4-8957-8aa7b6029018    # The volume type UUID\n",
    "allowVolumeExpansion: true                            # MUST set this value to turn on volume expansion feature\n",
    "---\n",
    "\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: my-expansion-pvc                           # [2] The PVC name, CAN be changed\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 20Gi                                # [3] The PVC size, CAN be changed, this value MUST be in the valid range of the proper volume type\n",
    "  storageClassName: my-expansion-storage-class \n",
    "```\"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=\"V·∫≠y volume 100Gi th√¨ sao?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o', additional_kwargs={}, response_metadata={}, id='e695b379-3c4f-431f-a11a-277f331fb496'),\n",
       " HumanMessage(content='V·∫≠y volume 100Gi th√¨ sao?', additional_kwargs={}, response_metadata={}, id='91091fd5-68a0-4ebe-b6d2-458b93fd4995'),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}, id='f9a888b5-cdb4-4b45-8e67-f008c0cd8206')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    # trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    trimmed_messages = state[\"messages\"]\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "VKS l√† vi·∫øt t·∫Øt c·ªßa **VngCloud Kubernetes Service**, m·ªôt d·ªãch v·ª• c·ªßa VngCloud cung c·∫•p c√°c c·ª•m Kubernetes ƒë·∫øn kh√°ch h√†ng. \n",
      "\n",
      "N√≥i c√°ch kh√°c, VKS l√† m·ªôt n·ªÅn t·∫£ng qu·∫£n l√Ω Kubernetes ƒë∆∞·ª£c qu·∫£n l√Ω ƒë·∫ßy ƒë·ªß (fully managed) b·ªüi VngCloud. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† VngCloud s·∫Ω x·ª≠ l√Ω t·∫•t c·∫£ c√°c kh√≠a c·∫°nh c·ªßa vi·ªác v·∫≠n h√†nh v√† b·∫£o tr√¨ c·ª•m Kubernetes, bao g·ªìm:\n",
      "\n",
      "* **C√†i ƒë·∫∑t v√† c·∫•u h√¨nh:** VngCloud s·∫Ω c√†i ƒë·∫∑t v√† c·∫•u h√¨nh c·ª•m Kubernetes cho b·∫°n, ƒë·∫£m b·∫£o r·∫±ng n√≥ ho·∫°t ƒë·ªông tr∆°n tru v√† an to√†n.\n",
      "* **Qu·∫£n l√Ω:** VngCloud s·∫Ω qu·∫£n l√Ω c·ª•m Kubernetes c·ªßa b·∫°n, bao g·ªìm c·∫≠p nh·∫≠t ph·∫ßn m·ªÅm, b·∫£o tr√¨ h·ªá th·ªëng v√† x·ª≠ l√Ω c√°c s·ª± c·ªë.\n",
      "* **B·∫£o m·∫≠t:** VngCloud s·∫Ω ƒë·∫£m b·∫£o r·∫±ng c·ª•m Kubernetes c·ªßa b·∫°n ƒë∆∞·ª£c b·∫£o m·∫≠t kh·ªèi c√°c m·ªëi ƒëe d·ªça b√™n ngo√†i.\n",
      "* **Kh·∫£ nƒÉng m·ªü r·ªông:** VngCloud s·∫Ω cho ph√©p b·∫°n d·ªÖ d√†ng m·ªü r·ªông c·ª•m Kubernetes c·ªßa b·∫°n khi nhu c·∫ßu c·ªßa b·∫°n thay ƒë·ªïi.\n",
      "\n",
      "VKS cung c·∫•p m·ªôt lo·∫°t c√°c t√≠nh nƒÉng, bao g·ªìm:\n",
      "\n",
      "* **Fully managed Kubernetes:** VngCloud s·∫Ω x·ª≠ l√Ω t·∫•t c·∫£ c√°c kh√≠a c·∫°nh c·ªßa vi·ªác v·∫≠n h√†nh v√† b·∫£o tr√¨ c·ª•m Kubernetes c·ªßa b·∫°n.\n",
      "* **Autoscaling:** VKS s·∫Ω t·ª± ƒë·ªông m·ªü r·ªông ho·∫∑c thu nh·ªè c·ª•m Kubernetes c·ªßa b·∫°n d·ª±a tr√™n nhu c·∫ßu c·ªßa b·∫°n.\n",
      "* **Monitoring:** VKS s·∫Ω theo d√µi hi·ªáu su·∫•t c·ªßa c·ª•m Kubernetes c·ªßa b·∫°n v√† cung c·∫•p cho b·∫°n c√°c th√¥ng tin chi ti·∫øt v·ªÅ ho·∫°t ƒë·ªông c·ªßa n√≥.\n",
      "* **Logging:** VKS s·∫Ω ghi l·∫°i t·∫•t c·∫£ c√°c ho·∫°t ƒë·ªông c·ªßa c·ª•m Kubernetes c·ªßa b·∫°n, gi√∫p b·∫°n d·ªÖ d√†ng g·ª° l·ªói v√† kh·∫Øc ph·ª•c s·ª± c·ªë.\n",
      "* **Networking:** VKS cung c·∫•p c√°c t√≠nh nƒÉng m·∫°ng n√¢ng cao, bao g·ªìm m·∫°ng d·ªãch v·ª•, m·∫°ng pod v√† m·∫°ng ingress.\n",
      "* **Security:** VKS cung c·∫•p c√°c t√≠nh nƒÉng b·∫£o m·∫≠t n√¢ng cao, bao g·ªìm x√°c th·ª±c, ·ªßy quy·ªÅn v√† m√£ h√≥a.\n",
      "\n",
      "VKS l√† m·ªôt gi·∫£i ph√°p l√Ω t∆∞·ªüng cho c√°c doanh nghi·ªáp mu·ªën tri·ªÉn khai c√°c ·ª©ng d·ª•ng container h√≥a m·ªôt c√°ch nhanh ch√≥ng v√† d·ªÖ d√†ng. N√≥ cung c·∫•p m·ªôt n·ªÅn t·∫£ng m·∫°nh m·∫Ω v√† ƒë√°ng tin c·∫≠y ƒë·ªÉ ch·∫°y c√°c ·ª©ng d·ª•ng container h√≥a c·ªßa b·∫°n, ƒë·ªìng th·ªùi cho ph√©p b·∫°n t·∫≠p trung v√†o vi·ªác ph√°t tri·ªÉn ·ª©ng d·ª•ng c·ªßa m√¨nh thay v√¨ qu·∫£n l√Ω c∆° s·ªü h·∫° t·∫ßng.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"VKS l√† g√¨?\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "B·∫°n c√≥ th·ªÉ t·∫°o PersistentVolumeClaim 100Gi tr√™n VKS b·∫±ng c√°ch s·ª≠ d·ª•ng file YAML sau:\n",
      "\n",
      "```yaml\n",
      "apiVersion: v1\n",
      "kind: PersistentVolumeClaim\n",
      "metadata:\n",
      "  name: my-pvc\n",
      "spec:\n",
      "  accessModes:\n",
      "    - ReadWriteOnce\n",
      "  resources:\n",
      "    requests:\n",
      "      storage: 100Gi\n",
      "  storageClassName: my-storage-class\n",
      "```\n",
      "\n",
      "**Gi·∫£i th√≠ch:**\n",
      "\n",
      "* **apiVersion:** Phi√™n b·∫£n API c·ªßa Kubernetes.\n",
      "* **kind:** Lo·∫°i ƒë·ªëi t∆∞·ª£ng, trong tr∆∞·ªùng h·ª£p n√†y l√† PersistentVolumeClaim.\n",
      "* **metadata:** Th√¥ng tin meta c·ªßa PersistentVolumeClaim, bao g·ªìm t√™n.\n",
      "* **spec:** C·∫•u h√¨nh c·ªßa PersistentVolumeClaim.\n",
      "* **accessModes:** Ch·∫ø ƒë·ªô truy c·∫≠p v√†o PersistentVolumeClaim. Trong tr∆∞·ªùng h·ª£p n√†y l√† ReadWriteOnce, cho ph√©p m·ªôt pod duy nh·∫•t ghi v√†o PersistentVolumeClaim.\n",
      "* **resources:** Y√™u c·∫ßu t√†i nguy√™n cho PersistentVolumeClaim.\n",
      "    * **requests:** Y√™u c·∫ßu dung l∆∞·ª£ng l∆∞u tr·ªØ l√† 100Gi.\n",
      "* **storageClassName:** T√™n c·ªßa StorageClass ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o PersistentVolumeClaim.\n",
      "\n",
      "**L∆∞u √Ω:**\n",
      "\n",
      "* B·∫°n c·∫ßn thay th·∫ø `my-storage-class` b·∫±ng t√™n c·ªßa StorageClass m√† b·∫°n mu·ªën s·ª≠ d·ª•ng.\n",
      "* B·∫°n c·∫ßn ƒë·∫£m b·∫£o r·∫±ng StorageClass ƒë∆∞·ª£c s·ª≠ d·ª•ng h·ªó tr·ª£ dung l∆∞·ª£ng l∆∞u tr·ªØ 100Gi.\n",
      "\n",
      "**C√°ch t·∫°o PersistentVolumeClaim:**\n",
      "\n",
      "1. L∆∞u file YAML tr√™n v·ªõi t√™n `my-pvc.yaml`.\n",
      "2. S·ª≠ d·ª•ng l·ªánh `kubectl apply -f my-pvc.yaml` ƒë·ªÉ t·∫°o PersistentVolumeClaim.\n",
      "\n",
      "Sau khi t·∫°o PersistentVolumeClaim, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng n√≥ trong Deployment ho·∫∑c StatefulSet ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu cho ·ª©ng d·ª•ng c·ªßa b·∫°n.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"T·∫°o PersistentVolumeClaim 100Gi tr√™n VKS\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "C√¢u h·ªèi b·∫°n v·ª´a h·ªèi t√¥i l√†: \"V·∫≠y volume 100Gi th√¨ sao?\". \n",
      "\n",
      "B·∫°n mu·ªën h·ªèi v·ªÅ vi·ªác t·∫°o m·ªôt PersistentVolumeClaim v·ªõi dung l∆∞·ª£ng 100Gi tr√™n VKS ph·∫£i kh√¥ng?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"C√¢u h·ªèi m√† t√¥i v·ª´a h·ªèi b·∫°n l√† g√¨ v·∫≠y\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##| ƒêo·∫°n rap trong b√†i h√°t \"Em c·ªßa ng√†y h√¥m qua\" c·ªßa S∆°n| T√πng MTP:\n",
      "\n",
      "**Verse 2:**\n",
      "\n",
      "(Rap)\n",
      "|Anh nh·ªõ em, em c·ªßa ng√†y h√¥m qua\n",
      "N·ª• c∆∞·ªùi, √°nh m·∫Øt, n·ª• h√¥n, l·ªùi h·ª©a\n",
      "Gi·ªù ƒë√¢y ƒë√£ xa, nh∆∞| m·ªôt gi·∫•c m∆°\n",
      "ƒê·ªÉ l·∫°i trong anh, n·ªói nh·ªõ, ni·ªÅm ƒëau\n",
      "\n",
      "Anh nh·ªõ em, em c·ªßa ng√†y h√¥m qua\n",
      "T√¨nh y√™u, h·∫°nh ph√∫c,| gi·ªù ƒë√¢y ƒë√£ phai nh·∫°t\n",
      "Ch·ªâ c√≤n l·∫°i trong anh, m·ªôt n·ªói c√¥ ƒë∆°n\n",
      "V√† nh·ªØng k·ª∑ ni·ªám, nh∆∞ nh·ªØng v·∫øt th∆∞∆°ng l√≤ng\n",
      "\n",
      "Anh nh·ªõ em, em c·ªßa ng√†y h√¥m qua\n",
      "Nh∆∞ng em ƒë√£ ƒëi, ƒë·ªÉ l·∫°i anh| m·ªôt m√¨nh\n",
      "Trong ƒë√™m t·ªëi, anh l·∫°c l·ªëi, kh√¥ng t√¨m th·∫•y em\n",
      "Ch·ªâ c√≤n l·∫°i n·ªói nh·ªõ, nh∆∞ m·ªôt l·ªùi nguy·ªÅn\n",
      "\n",
      "**L∆∞u √Ω:** ƒê√¢y l√† ƒëo·∫°n rap trong b√†i h√°t \"Em c·ªßa ng√†y h√¥m qua\" c·ªßa S∆°n| T√πng MTP. \n",
      "|"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Cho t√¥i xin l·ªùi b√†i h√°t Em c·ªßa ng√†y h√¥m qua c·ªßa S∆°n T√πng MTP (ƒëo·∫°n rap)\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
