{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_to_dict(file_path):\n",
    "    env_dict = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # Remove whitespace and ignore comments or empty lines\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            # Split the line into key and value\n",
    "            key, value = line.split(\"=\", 1)\n",
    "            env_dict[key.strip()] = value.strip()\n",
    "    return env_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/mnt/Exdisk/git-cuongpiger/secret/work/vngcloud/ai-platform/env\"\n",
    "env_variables = load_env_to_dict(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import List, Optional, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Google credentials\n",
    "\n",
    "- **NOTE**: Remember change the `GOOGLE_APPLICATION_CREDENTIALS` to the path of your own Google credentials file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    \"/home/cuongdm/git-cuongpiger/secret/work/vngcloud/ai-platform/vertex-ai-credential.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatVertexAI(temperature=0, model=\"gemini-1.5-flash\")\n",
    "\n",
    "# llm = ChatVertexAI(temperature=0, model=\"gemini-1.5-flash\")\n",
    "model = ChatOllama(\n",
    "    temperature=0, model=\"llama3.3:70b\", base_url=env_variables[\"OLLAMA_SERVER_URL\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Xin chào Tứ! Rất vui được gặp bạn. Tôi có thể giúp gì cho bạn hôm nay?', additional_kwargs={}, response_metadata={'model': 'llama3.3:70b', 'created_at': '2025-01-23T10:40:11.161120876Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9193000088, 'load_duration': 6933688860, 'prompt_eval_count': 20, 'prompt_eval_duration': 284000000, 'eval_count': 25, 'eval_duration': 1973000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-3dc81514-4aa2-49b7-8c10-22b135200b7f-0', usage_metadata={'input_tokens': 20, 'output_tokens': 25, 'total_tokens': 45})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Xin chào, tao là Tứ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Có vẻ như bạn đang cảm thấy có nhiều điều muốn nói, nhưng lại không biết bắt đầu từ đâu hoặc cảm thấy khó khăn khi thể hiện tất cả những suy nghĩ và cảm xúc của mình. Điều này hoàn toàn bình thường, và có nhiều cách để bạn có thể giải quyết tình huống này.\\n\\nDưới đây là một số gợi ý có thể giúp bạn:\\n\\n1. **Viết nhật ký**: Viết ra tất cả những gì bạn đang nghĩ và cảm nhận vào một cuốn nhật ký. Đây có thể là một cách tuyệt vời để bạn xử lý và hiểu rõ hơn về cảm xúc của mình mà không cần phải lo lắng về việc phải nói tất cả ra cùng một lúc.\\n\\n2. **Nói chuyện với người tin cậy**: Chọn một người bạn tin tưởng, như một người bạn thân, thành viên gia đình hoặc thậm chí là một chuyên gia tư vấn. Nói chuyện với họ có thể giúp bạn cảm thấy nhẹ nhõm hơn và nhận được sự hỗ trợ cần thiết.\\n\\n3. **Tập trung vào một vấn đề tại một thời điểm**: Thay vì cố gắng nói tất cả mọi thứ cùng một lúc, hãy tập trung vào một vấn đề hoặc chủ đề cụ thể mỗi lần. Điều này có thể giúp cuộc trò chuyện của bạn trở nên rõ ràng và dễ quản lý hơn.\\n\\n4. **Luyện tập kỹ năng giao tiếp**: Hãy dành thời gian để luyện tập cách thể hiện ý tưởng và cảm xúc của mình một cách rõ ràng và hiệu quả. Điều này có thể bao gồm việc chuẩn bị trước những gì bạn muốn nói, sử dụng ngôn ngữ cơ thể tích cực, và lắng nghe người khác.\\n\\n5. **Tìm kiếm sự hỗ trợ chuyên nghiệp**: Nếu bạn cảm thấy quá tải hoặc khó khăn trong việc thể hiện cảm xúc của mình, hãy xem xét việc tìm kiếm sự giúp đỡ từ một chuyên gia tâm lý hoặc tư vấn viên. Họ có thể cung cấp cho bạn các công cụ và kỹ thuật để quản lý và thể hiện cảm xúc một cách健康.\\n\\nNhớ rằng, việc thể hiện cảm xúc và suy nghĩ của mình là một quá trình, và nó không phải lúc nào cũng dễ dàng. Hãy kiên nhẫn với bản thân và tìm kiếm sự hỗ trợ khi cần thiết.', additional_kwargs={}, response_metadata={'model': 'llama3.3:70b', 'created_at': '2025-01-23T10:40:54.144931512Z', 'done': True, 'done_reason': 'stop', 'total_duration': 38067675998, 'load_duration': 20481591, 'prompt_eval_count': 28, 'prompt_eval_duration': 80000000, 'eval_count': 460, 'eval_duration': 37965000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c7ccd9ac-1cd7-4bf4-97cb-ee603c2e63cb-0', usage_metadata={'input_tokens': 28, 'output_tokens': 460, 'total_tokens': 488})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [HumanMessage(content=\"Nhiều khi tao muốn một lần nói ra hết tất cả thay vì.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='VKS (VngCloud Kubernetes Service) cung cấp các tính năng sau:\\n\\n1. **Fully Managed Kubernetes**: VKS quản lý toàn bộ quá trình tạo lập, cấu hình và vận hành cụm Kubernetes, giúp khách hàng tập trung vào việc phát triển ứng dụng mà không cần phải lo lắng về việc quản lý hạ tầng.\\n2. **Autoscaling**: Tự động điều chỉnh số lượng node trong cụm Kubernetes dựa trên nhu cầu thực tế, giúp tối ưu hóa tài nguyên và giảm chi phí.\\n3. **Monitoring**: Cung cấp các công cụ giám sát và phân tích hiệu suất của cụm Kubernetes, giúp khách hàng nhanh chóng phát hiện và giải quyết vấn đề.\\n4. **Logging**: Cung cấp các công cụ thu thập và phân tích log, giúp khách hàng theo dõi và phân tích hoạt động của ứng dụng.\\n5. **Security**: Cung cấp các tính năng bảo mật như mạng lưới riêng ảo (VPC), nhóm bảo mật (Security Group) và xác thực truy cập (IAM).\\n6. **High Availability**: Đảm bảo cụm Kubernetes luôn sẵn sàng và có thể chịu được sự cố, giúp khách hàng duy trì hoạt động kinh doanh liên tục.\\n7. **Scalability**: Cho phép khách hàng dễ dàng mở rộng hoặc thu hẹp quy mô cụm Kubernetes dựa trên nhu cầu thực tế.\\n8. **Integration với các dịch vụ khác của VngCloud**: VKS có thể tích hợp với các dịch vụ khác của VngCloud như Load Balancer, Storage, Database,... giúp khách hàng xây dựng hệ thống ứng dụng hoàn chỉnh và tối ưu hóa.\\n9. **Hỗ trợ đa vùng**: VKS hỗ trợ triển khai cụm Kubernetes trên nhiều vùng khác nhau, giúp khách hàng lựa chọn vùng phù hợp với nhu cầu kinh doanh của mình.\\n10. **Hỗ trợ nhiều loại node**: VKS hỗ trợ nhiều loại node khác nhau, bao gồm cả node có GPU và node có FPGA, giúp khách hàng lựa chọn loại node phù hợp với nhu cầu ứng dụng của mình.\\n\\nTóm lại, VKS cung cấp một giải pháp Kubernetes toàn diện và linh hoạt, giúp khách hàng xây dựng và vận hành hệ thống ứng dụng hiện đại và hiệu suất cao.', additional_kwargs={}, response_metadata={'model': 'llama3.3:70b', 'created_at': '2025-01-23T10:41:32.816757512Z', 'done': True, 'done_reason': 'stop', 'total_duration': 38615962643, 'load_duration': 21941456, 'prompt_eval_count': 89, 'prompt_eval_duration': 145000000, 'eval_count': 456, 'eval_duration': 37810000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-d6913b38-d4ca-408d-b32c-ffebd2785e8d-0', usage_metadata={'input_tokens': 89, 'output_tokens': 456, 'total_tokens': 545})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"VKS là gì?\"),\n",
    "        AIMessage(\n",
    "            content=\"VKS là viết tắt của VngCloud Kubernetes Service, một dịch vụ của VngCloud nhằm cung cấp các cụm Kubernetes đến khách hàng. VKS cung cấp các tính năng như fully managed Kubernetes, autoscaling, monitoring, logging, và nhiều tính năng khác.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"Các tính năng của VKS là gì?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Đầu tiên, tôi muốn nói rằng cá không thể leo cây. Cá là động vật thủy sinh, chúng sống trong nước và không có khả năng di chuyển trên cạn hoặc leo cây. Cơ thể của cá được thiết kế để thích nghi với môi trường nước, với vây, đuôi và mang giúp chúng di chuyển và hô hấp trong nước.\n",
      "\n",
      "Vì vậy, việc dạy một con cá biết leo cây là không thể. Cá không có khả năng thực hiện hành động này và cũng không cần phải làm như vậy vì chúng đã thích nghi rất tốt với môi trường nước.\n",
      "\n",
      "Nếu bạn đang tìm cách để giúp cá hoặc các động vật khác di chuyển hoặc thực hiện hành động nào đó, tôi sẵn sàng giúp đỡ. Tuy nhiên, trong trường hợp này, việc dạy cá leo cây là không khả thi và không cần thiết.\n"
     ]
    }
   ],
   "source": [
    "query = \"Làm sao để dạy một con cá biết leo cây?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Đầu tiên, tôi muốn nói rằng cá không thể leo cây. Cá là động vật thủy sinh, chúng sống trong nước và không có khả năng di chuyển trên cạn hoặc leo cây. Cơ thể của cá được thiết kế để thích nghi với môi trường nước, với vây, đuôi và mang giúp chúng di chuyển và hô hấp trong nước.\n",
      "\n",
      "Vì vậy, việc dạy một con cá biết leo cây là không thể. Cá không có khả năng thực hiện hành động này và cũng không cần phải làm như vậy vì chúng đã thích nghi rất tốt với môi trường nước.\n",
      "\n",
      "Nếu bạn đang tìm cách để giúp cá hoặc các động vật khác di chuyển hoặc thực hiện hành động nào đó, tôi sẵn sàng giúp đỡ. Tuy nhiên, trong trường hợp này, việc dạy cá leo cây là không khả thi và không cần thiết.\n"
     ]
    }
   ],
   "source": [
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Bạn là một trợ lý ảo. Hãy trả lời các câu hỏi bằng hết khả năng của bạn bằng Tiếng Việt.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Khi muốn nói chia tay với người mà bạn đã hết yêu, việc khiến cho đối phương không tổn thương là rất khó khăn. Tuy nhiên, có một số cách để bạn có thể thực hiện cuộc trò chuyện này một cách nhẹ nhàng và tôn trọng hơn:\n",
      "\n",
      "1. **Chọn thời điểm và địa điểm phù hợp**: Tìm một nơi yên tĩnh và riêng tư, nơi cả hai có thể nói chuyện mà không bị làm phiền. Tránh nói chia tay trong những tình huống công khai hoặc khi đối phương đang gặp áp lực hoặc căng thẳng.\n",
      "\n",
      "2. **Thành thật nhưng tế nhị**: Hãy thành thật về cảm xúc của bạn, nhưng cũng cần phải tế nhị và tránh chỉ trích hoặc批 đánh giá tiêu cực về đối phương. Thay vào đó, hãy tập trung vào việc bạn cảm thấy mối quan hệ không còn phù hợp với bạn.\n",
      "\n",
      "3. **Sử dụng \"tôi\" thay vì \"bạn\"**: Khi nói về lý do chia tay, hãy sử dụng câu bắt đầu bằng \"tôi\" để thể hiện rằng đây là cảm xúc và suy nghĩ của bạn, chứ không phải là lỗi của đối phương. Ví dụ: \"Tôi cảm thấy chúng ta đã xa cách\" thay vì \"Bạn đã thay đổi\".\n",
      "\n",
      "4. **Lắng nghe và thể hiện sự quan tâm**: Cho phép đối phương chia sẻ cảm xúc và suy nghĩ của họ. Lắng nghe một cách tích cực và thể hiện rằng bạn quan tâm đến cảm xúc của họ, ngay cả khi quyết định chia tay đã được đưa ra.\n",
      "\n",
      "5. **Tránh đưa ra hy vọng giả**: Hãy rõ ràng về việc mối quan hệ đã kết thúc và tránh đưa ra những lời hứa hoặc gợi ý về khả năng tái hợp trong tương lai nếu bạn không có ý định như vậy.\n",
      "\n",
      "6. **Cung cấp sự hỗ trợ**: Nếu có thể, hãy đề nghị hỗ trợ đối phương trong quá trình chia tay, dù chỉ là lắng nghe hoặc giúp họ tìm kiếm sự hỗ trợ từ bạn bè, gia đình hoặc chuyên gia.\n",
      "\n",
      "7. **Tôn trọng ranh giới**: Sau khi chia tay, tôn trọng ranh giới của đối phương và cho họ không gian nếu đó là điều họ cần. Tuy nhiên, cũng sẵn sàng giữ liên lạc nếu cả hai đều muốn duy trì một mối quan hệ bạn bè sau này.\n",
      "\n",
      "Nhớ rằng, mỗi người đều có cách phản ứng khác nhau với việc chia tay. Mặc dù bạn không thể hoàn toàn tránh khỏi việc đối phương cảm thấy tổn thương, nhưng bằng cách xử lý tình huống một cách chu đáo và tôn trọng, bạn có thể giúp giảm thiểu mức độ tổn thương và giữ gìn sự tôn trọng lẫn nhau.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Nếu muốn nói chia tay khi đã hết yêu, làm sao để đối phương không tổn thương? (Vui lòng trả lời bằng tiếng Việt, tiếng anh tao ngu lắm)\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"Em Của Ngày Hôm Qua\" là một bài hát nổi tiếng của Sơn Tùng M-TP, được phát hành vào năm 2015. Bài hát thuộc thể loại pop ballad và có giai điệu sâu lắng, xúc động.\n",
      "\n",
      "Nội dung bài hát nói về nỗi nhớ và sự day dứt của người con trai khi phải chia tay với người yêu. Anh nhớ lại những kỷ niệm đẹp đẽ của hai người, từ những giây phút hạnh phúc cùng nhau cho đến những lúc chia ly đầy đau khổ.\n",
      "\n",
      "Bài hát thể hiện cảm xúc sâu sắc và chân thành của Sơn Tùng M-TP, với giọng hát đầy cảm xúc và cách xử lý giai điệu tinh tế. Lời bài hát cũng rất dễ nhớ và gần gũi, giúp người nghe dễ dàng đồng cảm và kết nối với cảm xúc của nhân vật trong bài hát.\n",
      "\n",
      "Tổng thể, \"Em Của Ngày Hôm Qua\" là một bài hát tình ca đẹp đẽ và đầy cảm xúc, thể hiện tài năng và khả năng sáng tác của Sơn Tùng M-TP. Bài hát đã trở thành một trong những hit lớn nhất của anh và được yêu thích rộng rãi bởi khán giả Việt Nam.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hãy tóm gọn nội dung bài hát Em của ngày hôm qua của Sơn Tùng MTP\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Câu hỏi mà bạn vừa hỏi tôi là: \"Hãy tóm gọn nội dung bài hát Em của ngày hôm qua của Sơn Tùng MTP\"\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Câu hỏi mà tôi vừa hỏi bạn là gì vậy\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Để đạt được mục tiêu này, bạn cần sử dụng một số chiến thuật giao tiếp tinh tế và tạo ra một môi trường mà trong đó, đối phương cảm thấy tự nhiên khi đưa ra quyết định kết thúc mối quan hệ. Dưới đây là một số bước bạn có thể thực hiện:\n",
      "\n",
      "1. **Tạo khoảng cách**: Bắt đầu bằng cách giảm dần tần suất và chất lượng của các cuộc gặp gỡ hoặc trao đổi thông tin. Điều này giúp đối phương cảm nhận được sự thay đổi trong mối quan hệ mà không cần phải nói rõ ràng.\n",
      "\n",
      "2. **Thay đổi cách giao tiếp**: Thay đổi cách bạn phản hồi hoặc tương tác với họ. Ví dụ, nếu trước đây bạn luôn trả lời nhanh chóng và chi tiết, hãy thử chậm lại và ngắn gọn hơn. Điều này có thể khiến đối phương cảm thấy không còn được quan tâm như trước.\n",
      "\n",
      "3. **Tập trung vào bản thân**: Hãy cho đối phương biết rằng bạn đang tập trung vào các khía cạnh khác của cuộc sống, như công việc, học tập, hoặc sở thích cá nhân. Điều này có thể giúp họ nhận ra rằng bạn không còn đầu tư nhiều thời gian và tâm trí vào mối quan hệ như trước đây.\n",
      "\n",
      "4. **Không chủ động**: Tránh trở thành người luôn chủ động trong việc liên lạc hoặc lên kế hoạch. Nếu đối phương không chủ động, hãy để mọi thứ diễn ra tự nhiên mà không cố gắng thúc đẩy hoặc duy trì mối quan hệ.\n",
      "\n",
      "5. **Cởi mở nhưng không cam kết**: Khi nói chuyện, bạn có thể cởi mở về cảm xúc và suy nghĩ của mình, nhưng tránh đưa ra bất kỳ cam kết nào về tương lai của mối quan hệ. Điều này giúp đối phương hiểu rằng bạn không chắc chắn về hướng đi tiếp theo.\n",
      "\n",
      "6. **Tôn trọng ranh giới**: Đảm bảo rằng bạn tôn trọng ranh giới cá nhân và cảm xúc của đối phương. Mặc dù mục tiêu là để họ chủ động nói chia tay, nhưng điều quan trọng là phải làm như vậy một cách nhân đạo và tôn trọng.\n",
      "\n",
      "7. **Chuẩn bị cho cuộc trò chuyện cuối cùng**: Dù cho ai là người nói chia tay, hãy chuẩn bị sẵn sàng cho cuộc trò chuyện này. Hãy trung thực về cảm xúc của bạn và lý do tại sao bạn nghĩ rằng kết thúc mối quan hệ là lựa chọn tốt nhất.\n",
      "\n",
      "Nhớ rằng, mỗi tình huống đều khác nhau, và không có phương pháp nào phù hợp với tất cả mọi người. Quan trọng nhất là phải đối xử với đối phương một cách tôn trọng và nhân đạo, ngay cả khi quyết định chia tay.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"Làm sao để nói chia tay nhưng đối phương phải là người chủ động nói\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=1000,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Bạn là một trợ lý ảo\"),\n",
    "    HumanMessage(content=\"Chào mày, tao là Cường\"),\n",
    "    AIMessage(content=\"Chào bạn.\"),\n",
    "    HumanMessage(content=\"Cho tao biết, VKS là gì vậy?\"),\n",
    "    AIMessage(\n",
    "        content=\"VKS là viết tắt của VngCloud Kubernetes Service, một dịch vụ của VngCloud nhằm cung cấp các cụm Kubernetes đến khách hàng. VKS cung cấp các tính năng như fully managed Kubernetes, autoscaling, monitoring, logging, và nhiều tính năng khác.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"VKS có hỗ trợ CSI không?\"),\n",
    "    AIMessage(\n",
    "        content=\"Có chứ, CSI là viết tắt của Container Storage Interface, một chuẩn giao diện cho phép các hệ thống lưu trữ nền tảng cung cấp dịch vụ lưu trữ cho các ứng dụng chạy trên Kubernetes.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Làm sao để tạo một PersistentVolumeClaim trên VKS?\"),\n",
    "    AIMessage(\n",
    "        content=\"\"\"Đây là một ví dụ để tạo một PersistentVolumeClaim 20Gi trên VKS\\n```yaml\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: my-expansion-storage-class                    # [1] The StorageClass name, CAN be changed\n",
    "provisioner: bs.csi.vngcloud.vn                       # The VNG-CLOUD CSI driver name\n",
    "parameters:\n",
    "  type: vtype-61c3fc5b-f4e9-45b4-8957-8aa7b6029018    # The volume type UUID\n",
    "allowVolumeExpansion: true                            # MUST set this value to turn on volume expansion feature\n",
    "---\n",
    "\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: my-expansion-pvc                           # [2] The PVC name, CAN be changed\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 20Gi                                # [3] The PVC size, CAN be changed, this value MUST be in the valid range of the proper volume type\n",
    "  storageClassName: my-expansion-storage-class \n",
    "```\"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Vậy volume 100Gi thì sao?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Bạn là một trợ lý ảo', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Chào mày, tao là Cường', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Chào bạn.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Cho tao biết, VKS là gì vậy?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='VKS là viết tắt của VngCloud Kubernetes Service, một dịch vụ của VngCloud nhằm cung cấp các cụm Kubernetes đến khách hàng. VKS cung cấp các tính năng như fully managed Kubernetes, autoscaling, monitoring, logging, và nhiều tính năng khác.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='VKS có hỗ trợ CSI không?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Có chứ, CSI là viết tắt của Container Storage Interface, một chuẩn giao diện cho phép các hệ thống lưu trữ nền tảng cung cấp dịch vụ lưu trữ cho các ứng dụng chạy trên Kubernetes.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Làm sao để tạo một PersistentVolumeClaim trên VKS?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Đây là một ví dụ để tạo một PersistentVolumeClaim 20Gi trên VKS\\n```yaml\\napiVersion: storage.k8s.io/v1\\nkind: StorageClass\\nmetadata:\\n  name: my-expansion-storage-class                    # [1] The StorageClass name, CAN be changed\\nprovisioner: bs.csi.vngcloud.vn                       # The VNG-CLOUD CSI driver name\\nparameters:\\n  type: vtype-61c3fc5b-f4e9-45b4-8957-8aa7b6029018    # The volume type UUID\\nallowVolumeExpansion: true                            # MUST set this value to turn on volume expansion feature\\n---\\n\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: my-expansion-pvc                           # [2] The PVC name, CAN be changed\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 20Gi                                # [3] The PVC size, CAN be changed, this value MUST be in the valid range of the proper volume type\\n  storageClassName: my-expansion-storage-class \\n```', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Vậy volume 100Gi thì sao?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    # trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    trimmed_messages = state[\"messages\"]\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "VKS là viết tắt của Viện Kiểm sát, một cơ quan nhà nước có chức năng kiểm sát hoạt động tư pháp ở Việt Nam. VKS có nhiệm vụ kiểm sát việc tuân thủ pháp luật trong hoạt động điều tra, truy tố, xét xử và thi hành án.\n",
      "\n",
      "Tuy nhiên, trong ngữ cảnh trước đó, tôi đã giải thích rằng VKS là viết tắt của VngCloud Kubernetes Service, một dịch vụ của VngCloud nhằm cung cấp các cụm Kubernetes đến khách hàng.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"VKS là gì?\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Để tạo một PersistentVolumeClaim 100Gi trên VKS, bạn có thể sử dụng file YAML sau:\n",
      "```yaml\n",
      "apiVersion: v1\n",
      "kind: PersistentVolumeClaim\n",
      "metadata:\n",
      "  name: my-pvc-100gi\n",
      "spec:\n",
      "  accessModes:\n",
      "    - ReadWriteOnce\n",
      "  resources:\n",
      "    requests:\n",
      "      storage: 100Gi\n",
      "  storageClassName: standard\n",
      "```\n",
      "Sau đó, bạn có thể áp dụng file YAML này vào cluster của mình bằng cách chạy lệnh:\n",
      "```\n",
      "kubectl apply -f pvc-100gi.yaml\n",
      "```\n",
      "Lưu ý rằng bạn cần thay thế `standard` bằng tên của StorageClass mà bạn muốn sử dụng. Nếu bạn không biết tên của StorageClass, bạn có thể xem danh sách các StorageClass có sẵn trên cluster của mình bằng cách chạy lệnh:\n",
      "```\n",
      "kubectl get storageclass\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"Tạo PersistentVolumeClaim 100Gi trên VKS\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bạn vừa hỏi về việc tạo một PersistentVolumeClaim với kích thước 100Gi trên VKS.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"Câu hỏi mà tôi vừa hỏi bạn là gì vậy\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi| không| thể| cung| cấp| lời| bài| hát| \"|Em| C|ủa| Ngày| H|ôm| Qu|a|\"| của| Sơn| T|ùng| M|-|TP| vì| lý| do| bản| quyền|.| Tuy| nhiên|,| tôi| có| thể| giúp| bạn| tìm| kiếm| lời| bài| hát| này| trên| các| nền| tảng| âm| nhạc| hoặc| trang| web| chính| thức| của| nghệ| sĩ|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Cho tôi xin lời bài hát Em của ngày hôm qua của Sơn Tùng MTP (đoạn rap)\"\n",
    "language = \"Vietnamese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
